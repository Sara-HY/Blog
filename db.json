{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/intent_input.png","path":"images/intent_input.png","modified":1,"renderable":0},{"_id":"source/images/intent_frame.png","path":"images/intent_frame.png","modified":1,"renderable":0},{"_id":"source/images/intent_f1.png","path":"images/intent_f1.png","modified":1,"renderable":0},{"_id":"source/images/intent_frame_baseline.png","path":"images/intent_frame_baseline.png","modified":1,"renderable":0},{"_id":"source/images/intent_frame_model.png","path":"images/intent_frame_model.png","modified":1,"renderable":0},{"_id":"source/images/intent_hlstm.png","path":"images/intent_hlstm.png","modified":1,"renderable":0},{"_id":"source/images/intent_dstc_rnn.png","path":"images/intent_dstc_rnn.png","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"source/images/intent_results.png","path":"images/intent_results.png","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"132c111853a1cf13cb23a5faf4694bf2cf8df2be","modified":1541405193908},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1540894722175},{"_id":"themes/next/.all-contributorsrc","hash":"e32dc4075e304af04b98d0726d489081bea722c0","modified":1540894722175},{"_id":"source/google10bb50e0b38f396b.html","hash":"1ee7a6da9197409280def29033e0a3a5629a7e32","modified":1540905840475},{"_id":"themes/next/.gitignore","hash":"a18c2e83bb20991b899b58e6aeadcb87dd8aa16e","modified":1540894722177},{"_id":"themes/next/.eslintrc.json","hash":"cc5f297f0322672fe3f684f823bc4659e4a54c41","modified":1540894722175},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1540894722175},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1540894722178},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1540894722175},{"_id":"themes/next/.travis.yml","hash":"3d1dc928c4a97933e64379cfde749dedf62f252c","modified":1540894722178},{"_id":"themes/next/LICENSE.md","hash":"fc7227c508af3351120181cbf2f9b99dc41f063e","modified":1540894722178},{"_id":"themes/next/bower.json","hash":"23379fec9b4f70bc2611433ac3770445a8ca18d9","modified":1540894722179},{"_id":"themes/next/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1540894722179},{"_id":"themes/next/gulpfile.coffee","hash":"48d2f9fa88a4210308fc41cc7d3f6d53989f71b7","modified":1540894722184},{"_id":"themes/next/package.json","hash":"901c9bf4743df8f1806b5bcb5e93b54f6aee0ea3","modified":1540894722208},{"_id":"themes/next/README.md","hash":"ee7119baf976616a84d3c9c10fcab567995dc98e","modified":1540894722178},{"_id":"themes/next/_config.yml","hash":"530e1a0bdbda92d9e6d77e3a9827b72f6476bc41","modified":1541349642066},{"_id":"source/categories/index.md","hash":"2c2ba4b201afe11dfe8b79a1926dfb1951c8bbb2","modified":1540894722174},{"_id":"source/tags/index.md","hash":"a646cf4e1109228f6b7c730b86fce3c0bed1dd35","modified":1540894722174},{"_id":"source/_posts/first_step.md","hash":"d0f2659ac3eb8312f54793727d7cfda38d3c1ba5","modified":1541322671814},{"_id":"source/_posts/intent_slot.md","hash":"2d0dbc479e661c38e06de80062f6ea42c161dde9","modified":1541414670288},{"_id":"source/images/intent_input.png","hash":"d675f4a9e795484f2c37fcddce7e4017b8793549","modified":1541131032642},{"_id":"themes/next/.github/CODE_OF_CONDUCT.md","hash":"b63696d41f022525e40d7e7870c3785b6bc7536b","modified":1540894722176},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"a5335a99377069ae76fd993d488bc3eaf48f3a05","modified":1540894722176},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"00c25366764e6b9ccb40b877c60dc13b2916bbf7","modified":1540894722176},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"7abbb4c8a29b2c14e576a00f53dbc0b4f5669c13","modified":1540894722176},{"_id":"themes/next/.github/stale.yml","hash":"fd0856f6745db8bd0228079ccb92a662830cc4fb","modified":1540894722177},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1540894722177},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"141e989844d0b5ae2e09fb162a280715afb39b0d","modified":1540894722180},{"_id":"themes/next/docs/AUTHORS.md","hash":"7b24be2891167bdedb9284a682c2344ec63e50b5","modified":1540894722180},{"_id":"themes/next/docs/DATA-FILES.md","hash":"8e1962dd3e1b700169b3ae5bba43992f100651ce","modified":1540894722180},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"120750c03ec30ccaa470b113bbe39f3d423c67f0","modified":1540894722181},{"_id":"themes/next/docs/INSTALLATION.md","hash":"2bbdd6c1751b2b42ce9b9335da420c6026a483e9","modified":1540894722181},{"_id":"themes/next/docs/LICENSE","hash":"fe607fe22fc9308f6434b892a7f2d2c5514b8f0d","modified":1540894722181},{"_id":"themes/next/docs/MATH.md","hash":"e6023505dcccaef0b856102543585a13fc6af0b1","modified":1540894722181},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"ad57c168d12ba01cf144a1ea0627b2ffd1847d3e","modified":1540894722181},{"_id":"themes/next/layout/_layout.swig","hash":"85de0662a1b136277a72f8d8b4b1425a006f377e","modified":1540894722188},{"_id":"themes/next/layout/category.swig","hash":"5d955284a42f802a48560b4452c80906a5d1da02","modified":1540894722206},{"_id":"themes/next/layout/archive.swig","hash":"2b6450c6b6d2bcbcd123ad9f59922a5e323d77a5","modified":1540894722206},{"_id":"themes/next/layout/index.swig","hash":"c2a3896c64e96790edc10426ef586b6186a87f46","modified":1540894722206},{"_id":"themes/next/layout/page.swig","hash":"862b361852fb6d7a95bfb6077922410a33cd3126","modified":1540894722207},{"_id":"themes/next/layout/post.swig","hash":"318249db246a57e9422875a2457c6acfce974ba5","modified":1540894722207},{"_id":"themes/next/layout/tag.swig","hash":"ba402ce8fd55e80b240e019e8d8c48949b194373","modified":1540894722207},{"_id":"themes/next/layout/schedule.swig","hash":"3268dd3d90d8b0e142cfa1a2ebb23355baeda148","modified":1540894722207},{"_id":"themes/next/languages/de.yml","hash":"fb478c5040a4e58a4c1ad5fb52a91e5983d65a3a","modified":1540894722184},{"_id":"themes/next/languages/default.yml","hash":"c540c3a0d7db2d4239293c8783881962640b6c34","modified":1540894722185},{"_id":"themes/next/languages/en.yml","hash":"c540c3a0d7db2d4239293c8783881962640b6c34","modified":1540894722185},{"_id":"themes/next/languages/fr.yml","hash":"0162a85ae4175e66882a9ead1249fedb89200467","modified":1540894722185},{"_id":"themes/next/languages/it.yml","hash":"62ef41d0a9a3816939cb4d93a524e6930ab9c517","modified":1540894722185},{"_id":"themes/next/languages/id.yml","hash":"e7fb582e117a0785036dcdbb853a6551263d6aa6","modified":1540894722185},{"_id":"themes/next/languages/ja.yml","hash":"e331b15b1fda0f2285d25853f834682ab8dc3c39","modified":1540894722185},{"_id":"themes/next/languages/nl.yml","hash":"bb9ce8adfa5ee94bc6b5fac6ad24ba4605d180d3","modified":1540894722186},{"_id":"themes/next/languages/ko.yml","hash":"fae155018ae0efdf68669b2c7dd3f959c2e45cc9","modified":1540894722185},{"_id":"themes/next/languages/pt-BR.yml","hash":"bfc80c8a363fa2e8dde38ea2bc85cd19e15ab653","modified":1540894722186},{"_id":"themes/next/languages/pt.yml","hash":"3cb51937d13ff12fcce747f972ccb664840a9ef3","modified":1540894722186},{"_id":"themes/next/languages/ru.yml","hash":"db0644e738d2306ac38567aa183ca3e859a3980f","modified":1540894722186},{"_id":"themes/next/languages/tr.yml","hash":"c5f0c20743b1dd52ccb256050b1397d023e6bcd9","modified":1540894722187},{"_id":"themes/next/languages/vi.yml","hash":"8da921dd8335dd676efce31bf75fdd4af7ce6448","modified":1540894722187},{"_id":"themes/next/languages/zh-CN.yml","hash":"fbbf3a0b664ae8e927c700b0a813692b94345156","modified":1540894722187},{"_id":"themes/next/languages/zh-HK.yml","hash":"7903b96912c605e630fb695534012501b2fad805","modified":1540894722187},{"_id":"themes/next/scripts/helpers.js","hash":"a70bfad3efda76738dab12e28e8b75e3989ee3da","modified":1540894722208},{"_id":"themes/next/scripts/merge-configs.js","hash":"33afe97284d34542015d358a720823feeebef120","modified":1540894722208},{"_id":"themes/next/languages/zh-TW.yml","hash":"6e6d2cd8f4244cb1b349b94904cb4770935acefd","modified":1540894722187},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1540894722209},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1540894722258},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1540894722258},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1540894722258},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1540894722180},{"_id":"source/images/intent_frame.png","hash":"777c14e60195e28f7a7d70337b317ae8f3de24b7","modified":1541144098762},{"_id":"source/images/intent_f1.png","hash":"65871d1178789be68a95ff07defba29b40bfde42","modified":1541129471491},{"_id":"source/images/intent_frame_baseline.png","hash":"9a156d1c2723e56017e3e6180109b68e3d834942","modified":1541148754805},{"_id":"source/images/intent_frame_model.png","hash":"9c7fa05f1214bf92990c604ce56c03413e8a16db","modified":1541154672920},{"_id":"source/images/intent_hlstm.png","hash":"caa761afe4039ce40ce441c0e0322cb985dd9896","modified":1541130340953},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540894722241},{"_id":"source/images/intent_dstc_rnn.png","hash":"f96016561fbc376a220790b4d58c472f6ab9b5d5","modified":1541399865894},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"d6d20f60f77a76c77f8e65d0c9adbd79d0274557","modified":1540894722182},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"b1dd18d9b890b21718883ea1832e7e02a773104a","modified":1540894722182},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"6c5d69e94961c793da156217ecf1179e868d7ba1","modified":1540894722182},{"_id":"themes/next/docs/ru/README.md","hash":"c54e256ed11a84ee38f755d6f35a3e6e29a91dbc","modified":1540894722182},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"bd2c955d9b7b1b45bd74a4536717d547e03fcde3","modified":1540894722183},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"f3eec572a7d83542e2710a7404082014aaa1a5e7","modified":1540894722183},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"a45a791b49954331390d548ac34169d573ea5922","modified":1540894722183},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"6855402e2ef59aae307e8bd2a990647d3a605eb8","modified":1540894722182},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"b19a6e0ae96eb7c756fb5b1ba03934c7f9cbb3c3","modified":1540894722183},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"24cf2618d164440b047bb9396263de83bee5b993","modified":1540894722183},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"8ac2f5d2a023211d8d8ea626cbf6b8dea67ac201","modified":1540894722184},{"_id":"themes/next/docs/zh-CN/README.md","hash":"aa6808f4f587c1a97205fa9427ba96a366bcb288","modified":1540894722184},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"5da70d7fa0c988a66a469b9795d33d471a4a4433","modified":1540894722184},{"_id":"themes/next/layout/_custom/head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1540894722188},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1540894722188},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1540894722189},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1540894722188},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"0790ddbc349508d7ece45a9a4391d0a1cd7263cc","modified":1540894722189},{"_id":"themes/next/layout/_macro/post-related.swig","hash":"08fe30ce8909b920540231e36c97e28cfbce62b6","modified":1540894722189},{"_id":"themes/next/layout/_macro/reward.swig","hash":"bd5778d509c51f4b1d8da3a2bc35462929f08c75","modified":1540894722190},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"a9e1346b83cf99e06bed59a53fc069279751e52a","modified":1540894722190},{"_id":"themes/next/layout/_partials/breadcrumb.swig","hash":"6994d891e064f10607bce23f6e2997db7994010e","modified":1540894722190},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"1f3121ef66a4698fd78f34bf2594ef79a407c92c","modified":1540894722190},{"_id":"themes/next/layout/_partials/comments.swig","hash":"eafff2d623af8991844f34819a60e37ac11ef245","modified":1540894722190},{"_id":"themes/next/layout/_partials/footer.swig","hash":"d15a983de60d4c0bdd23cd31cd49de876ed2310c","modified":1540894722191},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1aaf32bed57b976c4c1913fd801be34d4838cc72","modified":1540894722192},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"dbe321bcf3cf45917cc11a3e3f50d8572bac2c70","modified":1540894722193},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"0a0129e926c27fffc6e7ef87fe370016bc7a4564","modified":1540894722195},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"ac3ad2c0eccdf16edaa48816d111aaf51200a54b","modified":1540894722196},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"6fc63d5da49cb6157b8792f39c7305b55a0d1593","modified":1540894722195},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"f380a10c792411eff82204305b097a288ed0b423","modified":1540894722197},{"_id":"themes/next/layout/_third-party/bookmark.swig","hash":"60001c8e08b21bf3a7afaf029839e1455340e95d","modified":1540894722201},{"_id":"themes/next/layout/_third-party/copy-code.swig","hash":"a8ab2035654dd06d94faf11a35750529e922d719","modified":1540894722202},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"f532ce257fca6108e84b8f35329c53f272c2ce84","modified":1540894722203},{"_id":"themes/next/layout/_third-party/github-banner.swig","hash":"cabd9640dc3027a0b3ac06f5ebce777e50754065","modified":1540894722203},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"927f19160ae14e7030df306fc7114ba777476282","modified":1540894722204},{"_id":"themes/next/layout/_third-party/pangu.swig","hash":"6b75c5fd76ae7cf0a7b04024510bd5221607eab3","modified":1540894722204},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1540894722204},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1540894722204},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"b0ca46e0d1ff4c08cb0a3a8c1994f20d0260cef9","modified":1540894722204},{"_id":"themes/next/scripts/tags/button.js","hash":"4b12c376bea894d23cca0f9fcb3d6518b6db279d","modified":1540894722209},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"f13430d9d1c9773b390787c2f046bb1f12a79878","modified":1540894722209},{"_id":"themes/next/scripts/tags/exturl.js","hash":"1412ce2ef59fa4137b697a507fd759ff067a2398","modified":1540894722209},{"_id":"themes/next/scripts/tags/full-image.js","hash":"e282bf5a7c70b3d354001e8f66d3bef1a4fbb79e","modified":1540894722209},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"981e01aaf45a1f0f23ce0796d03134f9e437aaca","modified":1540894722210},{"_id":"themes/next/scripts/tags/include-raw.js","hash":"5db59d56f4f4082382bf1c16722e6c383892b0c5","modified":1540894722210},{"_id":"themes/next/scripts/tags/label.js","hash":"f0ecd3b5773b19a6bd93a819dfe0c49ee418e4de","modified":1540894722210},{"_id":"themes/next/scripts/tags/note.js","hash":"adb945ba93ac487d46b969ca4e59d3681b8f8d1c","modified":1540894722210},{"_id":"themes/next/scripts/tags/tabs.js","hash":"e37761253d68a29593fe9ed2fe403f49b6e971de","modified":1540894722210},{"_id":"themes/next/source/css/main.styl","hash":"c26ca6e7b5bd910b9046d6722c8e00be672890e0","modified":1540894722241},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1540894722241},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1540894722242},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1540894722241},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1540894722242},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1540894722242},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1540894722243},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1540894722242},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1540894722243},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1540894722244},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1540894722243},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1540894722244},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1540894722244},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1540894722244},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1540894722245},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1540894722245},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1540894722245},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1540894722245},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1540894722245},{"_id":"themes/next/layout/_macro/post.swig","hash":"5767eccaf3951151e01c61189016932e9516c8b9","modified":1540894722189},{"_id":"source/images/intent_results.png","hash":"66dba505ee2feffe151e2bfedf2f3a4520de8bf4","modified":1541049873940},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540894722197},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540894722197},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540894722230},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540894722230},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540894722231},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540894722240},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540894722240},{"_id":"themes/next/layout/_macro/menu/menu-item.swig","hash":"d1b73c926109145e52605929b75914cc8b60fb89","modified":1540894722189},{"_id":"themes/next/layout/_macro/menu/menu-badge.swig","hash":"65c5e585982dae7ae1542cada71858b4ea1f73d6","modified":1540894722188},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"3db735d0cd2d449edf2674310ac1e7c0043cb357","modified":1540894722192},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"2082f5077551123e695e8afec471c9c44b436acb","modified":1540894722192},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"88b4b6051592d26bff59788acb76346ce4e398c2","modified":1540894722192},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"fd780171713aada5eb4f4ffed8e714617c8ae6be","modified":1540894722192},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"00bf33b3c557b8f7e9faf49b226ea6ff7df5cda0","modified":1540894722191},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1540894722191},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1540894722193},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"a7e376b087ae77f2e2a61ba6af81cde5af693174","modified":1540894722191},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"a33b29ccbdc2248aedff23b04e0627f435824406","modified":1540894722193},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1540894722194},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1540894722194},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1540894722194},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1540894722195},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1540894722194},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"cc865af4a3cb6d25a0be171b7fc919ade306bb50","modified":1540894722196},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"ea03fe9c98ddcfcc0ecfdbe5a2b622f9cde3b3a1","modified":1540894722197},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"ea03fe9c98ddcfcc0ecfdbe5a2b622f9cde3b3a1","modified":1540894722197},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1540894722197},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1540894722198},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1540894722198},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"07307f1f0e0e9858f2c7143cbdfcb2a9a92149ab","modified":1540894722198},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"fae69a0e1a1d42f7bb44e594a29857d94594698b","modified":1540894722199},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1540894722198},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"5dbeb640707a9c91357e373b9063a48c8e78f439","modified":1540894722199},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"438c6f5e6665d72f4ea7ee206011d669246f6102","modified":1540894722199},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1540894722198},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"c28f3f4aa31d7f996d26a97df6cd7ffa9bfd2cec","modified":1540894722200},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"beb53371c035b62e1a2c7bb76c63afbb595fe6e5","modified":1540894722199},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1540894722200},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1540894722201},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1540894722201},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1540894722200},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"fe8177e4698df764e470354b6acde8292a3515e0","modified":1540894722202},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"03ef008bc95e8e83232e5464a6c63d6157d33a5e","modified":1540894722201},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"2c74a96dd314e804d801f8773ac1b2e0a970fce3","modified":1540894722202},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"03e83f1311faafb7dddc2899042ed1cacd5c995e","modified":1540894722202},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"a6fc00ec7f5642aabd66aa1cf51c6acc5b10e012","modified":1540894722203},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"34421679cae6581697cd3ab7c3729eb220e3e3f5","modified":1540894722202},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"97dbc2035bcb5aa7eafb80a4202dc827cce34983","modified":1540894722203},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"9b9ff4cc6d5474ab03f09835a2be80e0dba9fe89","modified":1540894722203},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1540894722206},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1540894722205},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1540894722205},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"b15e10abe85b4270860a56c970b559baa258b2a8","modified":1540894722205},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1540894722229},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1540894722229},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"e1f6f59ad6e562dfe640ee4ed5d1ac9b6aba4114","modified":1540894722240},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"59961fb806a39c367fd19ad37268eee112be6729","modified":1540894722231},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"2640a54fa63bdd4c547eab7ce2fc1192cf0ccec8","modified":1540894722230},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1540894722240},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"c167eeb6b736f7b021fba98c38c2c21032ee1255","modified":1540894722240},{"_id":"themes/next/source/css/_variables/base.styl","hash":"f9b83d0385529e52ce7ba95ed5ed6b3d4e2419bb","modified":1540894722240},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"1f7f10c579e7703d0f6acb8b73f3d78a07d0c623","modified":1540894722246},{"_id":"themes/next/source/js/src/affix.js","hash":"a2aab233d99297435a5274bf512c3c753fe08e80","modified":1540894722246},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"1c41508b83cb0c4512e64b4d63afa1be954ce8ef","modified":1540894722246},{"_id":"themes/next/source/js/src/exturl.js","hash":"54825acc8de4793feac415be227b965428f4e97d","modified":1540894722246},{"_id":"themes/next/source/js/src/post-details.js","hash":"0dde5e6d4547587662a3256317a9d5d1db507692","modified":1540894722246},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1540894722246},{"_id":"themes/next/source/js/src/motion.js","hash":"b45d2c0d48f2c8e6a0621b8063845f76b89476cc","modified":1540894722246},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"d07b3776708d4ae79ed2037c4c7391d5c9b06b19","modified":1540894722247},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fa3c92968bcdbcb8d95a1729f7659d9753cbd077","modified":1540894722247},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1540894722248},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1540894722247},{"_id":"themes/next/source/js/src/utils.js","hash":"66f2ac658d6110f70a86f784d0c5d891a97c14bd","modified":1540894722247},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1540894722248},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1540894722248},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1540894722248},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1540894722257},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1540894722257},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1540894722256},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1540894722253},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"6958a97fde63e03983ec2394a4f8e408860fb42b","modified":1540894722205},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1540894722205},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"665b1813a1d6fbc3c5549a76e4f26cd62a804dde","modified":1540894722232},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"0bef9f0dc134215bc4d0984ba3a16a1a0b6f87ec","modified":1540894722233},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1540894722233},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1540894722234},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"f43c821ea272f80703862260b140932fe4aa0e1f","modified":1540894722234},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"2212511ae14258d93bec57993c0385e5ffbb382b","modified":1540894722234},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1540894722234},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"5e12572b18846250e016a872a738026478ceef37","modified":1540894722235},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1540894722236},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1540894722237},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"35f093fe4c1861661ac1542d6e8ea5a9bbfeb659","modified":1540894722237},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1540894722237},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"d5e8ea6336bc2e237d501ed0d5bbcbbfe296c832","modified":1540894722237},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"876b5d99061025cf485a3cac440624ded5734319","modified":1540894722238},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1540894722238},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1540894722238},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"05a5abf02e84ba8f639b6f9533418359f0ae4ecb","modified":1540894722238},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"ffa870c3fa37a48b01dc6f967e66f5df508d02bf","modified":1540894722239},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"41f9cdafa00e256561c50ae0b97ab7fcd7c1d6a2","modified":1540894722239},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"b4a2f1d031fe44452cf55ded8211cf018235073a","modified":1540894722211},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"5779cc8086b1cfde9bc4f1afdd85223bdc45f0a0","modified":1540894722239},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1540894722211},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1540894722211},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1540894722211},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1540894722212},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1540894722216},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1540894722224},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"aebbd86500d819c4532ab290c62b6f432bc2f878","modified":1540894722227},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"efc40a32487e0ac7b94b1ca81bdbdcc4ec8f2924","modified":1540894722228},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1540894722228},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1540894722228},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"b75256fe3768b1a37b6ff6dd7f9f0ff135a42067","modified":1540894722227},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"02d138ed65060e98f20bc5b1dd59a791222b7156","modified":1540894722228},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1540894722228},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"89267bd16ecbedd1958af7f0fb3f4f654d24fffa","modified":1540894722247},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1540894722249},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1540894722249},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1540894722254},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1540894722254},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1540894722249},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1540894722256},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1540894722252},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1540894722251},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1540894722235},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1540894722236},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1540894722237},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"39dee82d481dd9d44e33658960ec63e47cd0a715","modified":1540894722212},{"_id":"themes/next/source/css/_common/components/header/github-banner.styl","hash":"ee37e6c465b9b2a7e39175fccfcbed14f2db039b","modified":1540894722212},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"7cc3f36222494c9a1325c5347d7eb9ae53755a32","modified":1540894722213},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1540894722213},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1540894722213},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1540894722214},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"a6dc3c7eb81ef5117c28fa2245fff1adc02d0292","modified":1540894722214},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1540894722213},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1540894722213},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1540894722215},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"7dd9a0378ccff3e4a2003f486b1a34e74c20dac6","modified":1540894722215},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1540894722214},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1540894722215},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1540894722216},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1540894722217},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"fb451dc4cc0355b57849c27d3eb110c73562f794","modified":1540894722215},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"f2911a048e5c20ca2a059bd1087d98ac1c51681c","modified":1540894722216},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1540894722218},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"ca89b167d368eac50a4f808fa53ba67e69cbef94","modified":1540894722218},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1540894722217},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1540894722218},{"_id":"themes/next/source/css/_common/components/post/post-reading_progress.styl","hash":"f4e9f870baa56eae423a123062f00e24cc780be1","modified":1540894722219},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"417f05ff12a2aaca6ceeac8b7e7eb26e9440c4c3","modified":1540894722219},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1540894722218},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1540894722219},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"549a8a0b5301d32acd86a97f17340cdfcd46fb63","modified":1540894722220},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1540894722220},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1540894722220},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"fcbbf06b546c366d70b7d2ba5880b0be3ca1e8ea","modified":1540894722221},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1540894722221},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"6089cbf4c907fe198b6501e40dc937480d0be175","modified":1540894722221},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"578bb2d5f24cad39205bbafb4c39c7e9962b9fa9","modified":1540894722221},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"35c0350096921dd8e2222ec41b6c17a4ea6b44f2","modified":1540894722222},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"e18b90c97aaff027e795f5a0cb10476a71bf1c3a","modified":1540894722222},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1540894722222},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1540894722222},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1540894722222},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1540894722222},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"4427ed3250483ed5b7baad74fa93474bd1eda729","modified":1540894722223},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1540894722223},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"43bc58daa8d35d5d515dc787ceb21dd77633fe49","modified":1540894722223},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1540894722223},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"6ec8ea7b11a146777b6b8da0f71f0cc1dbd129df","modified":1540894722224},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1540894722224},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1540894722224},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1540894722224},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1540894722225},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1540894722224},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1540894722225},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1540894722226},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"5e340ee2407a4e39cd708794cfcc718a5f398d7b","modified":1540894722225},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1540894722226},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1540894722226},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1540894722226},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"76937db9702053d772f6758d9cea4088c2a6e2a3","modified":1540894722227},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"10e9bb3392826a5a8f4cabfc14c6d81645f33fe6","modified":1540894722225},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1540894722226},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1c18c91ab3c60169ebe654c80c968fd8458786a3","modified":1540894722227},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1540894722251},{"_id":"public/sitemap.xml","hash":"98783bfe740841c25801017804e276b51ac44d1f","modified":1541414711726},{"_id":"public/google10bb50e0b38f396b.html","hash":"8377b754b9595db435f34a2b629def5849b92435","modified":1541414711744},{"_id":"public/categories/index.html","hash":"07f3395a993d8baf609990bdd0c375647685ab12","modified":1541414711744},{"_id":"public/tags/index.html","hash":"cb3a04cca6589fc5e544d10e362d365faa76bb2b","modified":1541414711744},{"_id":"public/archives/index.html","hash":"0194add8fd905f16c6b17122734bfa667ce074ed","modified":1541414711744},{"_id":"public/archives/2018/index.html","hash":"5bcdc9143c619aac7141100ea4fabc2cc65953d2","modified":1541414711744},{"_id":"public/archives/2018/10/index.html","hash":"22fc92c054d6b94207b3dcd8be5009bc7862086c","modified":1541414711744},{"_id":"public/archives/2018/11/index.html","hash":"050f14663eb334a17173d259232e3caef990a7a9","modified":1541414711745},{"_id":"public/categories/Note/index.html","hash":"144479b9e3472778ceea7fcf9bd380d2cccb2dd3","modified":1541414711745},{"_id":"public/tags/Research/index.html","hash":"5d2f2220db85e313be66159383ce615bb9cd0344","modified":1541414711745},{"_id":"public/tags/Tools/index.html","hash":"1232ead751603744c12cc73902734df16301ac79","modified":1541414711745},{"_id":"public/2018/11/02/intent_slot/index.html","hash":"fd7d50b7a954150b5d3275ee9a3b822deed68a4f","modified":1541414711745},{"_id":"public/2018/10/30/first_step/index.html","hash":"8a1f5baeb14f3cca65ba52151219ed9c416b0b69","modified":1541414711745},{"_id":"public/index.html","hash":"3ec6930e2cc0476b4fb83beb18581096e649dd46","modified":1541414711745},{"_id":"public/images/intent_input.png","hash":"d675f4a9e795484f2c37fcddce7e4017b8793549","modified":1541414711749},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1541414711749},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1541414711749},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1541414711749},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1541414711749},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1541414711749},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1541414711749},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1541414711749},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1541414711749},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1541414711749},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1541414711749},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1541414711749},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1541414711749},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1541414711749},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1541414711749},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1541414711749},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1541414711749},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1541414711749},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1541414711749},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1541414711749},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1541414711749},{"_id":"public/images/intent_f1.png","hash":"65871d1178789be68a95ff07defba29b40bfde42","modified":1541414712326},{"_id":"public/images/intent_frame.png","hash":"777c14e60195e28f7a7d70337b317ae8f3de24b7","modified":1541414712326},{"_id":"public/images/intent_frame_baseline.png","hash":"9a156d1c2723e56017e3e6180109b68e3d834942","modified":1541414712333},{"_id":"public/images/intent_frame_model.png","hash":"9c7fa05f1214bf92990c604ce56c03413e8a16db","modified":1541414712333},{"_id":"public/images/intent_hlstm.png","hash":"caa761afe4039ce40ce441c0e0322cb985dd9896","modified":1541414712333},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1541414712333},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1541414712333},{"_id":"public/js/src/algolia-search.js","hash":"1f7f10c579e7703d0f6acb8b73f3d78a07d0c623","modified":1541414712340},{"_id":"public/js/src/affix.js","hash":"a2aab233d99297435a5274bf512c3c753fe08e80","modified":1541414712340},{"_id":"public/js/src/bootstrap.js","hash":"1c41508b83cb0c4512e64b4d63afa1be954ce8ef","modified":1541414712340},{"_id":"public/js/src/exturl.js","hash":"54825acc8de4793feac415be227b965428f4e97d","modified":1541414712340},{"_id":"public/js/src/post-details.js","hash":"0dde5e6d4547587662a3256317a9d5d1db507692","modified":1541414712340},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1541414712340},{"_id":"public/js/src/motion.js","hash":"b45d2c0d48f2c8e6a0621b8063845f76b89476cc","modified":1541414712340},{"_id":"public/js/src/scrollspy.js","hash":"fa3c92968bcdbcb8d95a1729f7659d9753cbd077","modified":1541414712341},{"_id":"public/js/src/utils.js","hash":"66f2ac658d6110f70a86f784d0c5d891a97c14bd","modified":1541414712341},{"_id":"public/js/src/scroll-cookie.js","hash":"d07b3776708d4ae79ed2037c4c7391d5c9b06b19","modified":1541414712341},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1541414712341},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1541414712341},{"_id":"public/js/src/schemes/pisces.js","hash":"89267bd16ecbedd1958af7f0fb3f4f654d24fffa","modified":1541414712341},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1541414712341},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1541414712341},{"_id":"public/css/main.css","hash":"d032c24536469db2e899dfae15f6e6b6174432c8","modified":1541414712341},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1541414712341},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1541414712341},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1541414712341},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1541414712341},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1541414712341},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1541414712341},{"_id":"public/images/intent_dstc_rnn.png","hash":"f96016561fbc376a220790b4d58c472f6ab9b5d5","modified":1541414712341},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1541414712341},{"_id":"public/images/intent_results.png","hash":"66dba505ee2feffe151e2bfedf2f3a4520de8bf4","modified":1541414712345}],"Category":[{"name":"Note","_id":"cjo46iqiy00061wzmm8gqqfjm"}],"Data":[],"Page":[{"_content":"google-site-verification: google10bb50e0b38f396b.html\nskip_render: googled6054e120f1a1419.html","source":"google10bb50e0b38f396b.html","raw":"google-site-verification: google10bb50e0b38f396b.html\nskip_render: googled6054e120f1a1419.html","date":"2018-10-30T13:24:00.475Z","updated":"2018-10-30T13:24:00.475Z","path":"google10bb50e0b38f396b.html","title":"","comments":1,"layout":"page","_id":"cjo46iqb300001wzm83vgjmi1","content":"google-site-verification: google10bb50e0b38f396b.html\nskip_render: googled6054e120f1a1419.html","site":{"data":{}},"excerpt":"","more":"google-site-verification: google10bb50e0b38f396b.html\nskip_render: googled6054e120f1a1419.html"},{"title":"categories","date":"2018-10-30T09:23:43.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-10-30 17:23:43\ntype: \"categories\"\n---\n","updated":"2018-10-30T10:18:42.174Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjo46iqc000011wzmxv4k05sf","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2018-10-30T09:23:49.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-10-30 17:23:49\ntype: \"tags\"\n---\n","updated":"2018-10-30T10:18:42.174Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjo46iqik00021wzmhkk3vbmy","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Review on Intent Classification and Slot Filling","date":"2018-11-02T02:41:02.000Z","_content":"\n自然语言理解（Natural Language Understanding, NLU）是NLP领域的一个分支，在自然语言理解的过程中，首先就是对意图（Intent）分类，然后接着对槽位（Slot）填充。\n\n<!--more-->\n\n意图分类时一个典型的文本分类的问题，常用的方法如下：\n- 基于规则的方法\n 用户人工定义一些匹配规则进行分类。\n- 机器学习的方法\n SVM, Decision Tree等等。\n- 深度学习的方法\n 目前更加推崇使用 End-to-End 的网络进行分类。\n\n最近收集了一些关于意图分类以及槽填充的相关的数据集以及对应的测试指标。\n\n## 中文数据集\n\n### [NLPCC 2018 Task4](http://tcci.ccf.org.cn/conference/2018/taskdata.php) - Spoken Language Understanding in Task-Oriented Dialogue Systems\n\n#### 数据描述 [1]\n这个数据集来源于某车载产品的真实日志数据，主要涉及音乐，导航以及打电话等等领域，11种意图以及15种槽值类型。其中包括 **5.8K** 次会话，总共有 **26K** 次叙述（Utterance）。特别地，这个数据集仅仅包含了用户的输入（没有系统的回复），并且针对错误的槽值进行了修正，如将“什话”修正为“神话”。\n\n - 训练集：4705次会话, 21352次叙述。\n - 验证集：1177次会话, 5350次叙述。 （训练集：验证集 约 4:1）\n\n数据格式\n``` bash\nsession ID    用户query              意图                       语义槽标注\n    1           打电话\t   phone_call.make_a_phone_call\t        打电话\n    1\t      我想听美观\t        music.play\t          我想听<song>美观</song>\n    1\t      我想听什话\t        music.play\t          我想听<song>什话||神话</song>\n```\n\n#### 评估方法\n这个比赛主要有两个评估方法:\n\n- 意图分类，评估方法为F1值，具体的计算方法如下：\n<div align=center>\n\t<img src=\"/images/intent_f1.png\" width = \"500\"/>\n</div>\n\n- 意图分类以及槽填充，评估方法是准确度。即意图分类以及所有的槽位都完全正确。\n\n#### 主要算法\n总共有16个队伍参加了这个比赛，但是只有两个队伍开源了他们的方法，分别是HLSTM-SLU模型和Sogou团队的模型。具体结果如下：\n<div align=center>\n\t<img src=\"/images/intent_results.png\" width = \"500\" align=center/>\n</div>\n\n##### HLSTM-SLU [2]\n这个可以看做是深度学习的方法和传统的机器学习方法相结合。模型结构如下：\n<div align=center>\n\t<img src=\"/images/intent_hlstm.png\" width = \"500\" align=center/>\n</div>\n\n这个模型主要由三个LSTM组成，两个双向LSTM处理输入和输出，一个单向LSTM处理一个会话中的多个叙述。\n\n- 输入Bi-LSTM\n 输入：Character Embedding + POS + Domain \n 其中POS表示对每个字进行词性标注，并用类似于BI的方法进行编码；Domain表示不同领域的词，也用BI的方法进行编码，具体实例如下：\n\n<div align=center>\n\t<img src=\"/images/intent_input.png\" width = \"500\" align=center/>\n</div>\n\n- Session LSTM\n 输入：一次对话中的每轮的描述经过输入Bi-LSTM的输出经过最大池化之后的结果。\n 输出：**意图的类别**\n\n- 输出Bi-LSTM\n 输入：Session LSTM + 输入Bi-LSTM\n 输出：**槽位标注**\n\n注：并没有直接使用LSTM的结果作为最终的结果，而是根据 **CRF** 预测最优的序列。\n\n**Trick**: 使用 **over sampling** 解决意图类别中的样本不均衡的问题，并在过程中使用规则识别了一部分小样本的意图。\n\n**结果**：这个模型在两个评估方法的结果最终为94.19%，90.84%。\n\n##### Sogou [3]\n这个模型没有使用深度学习的方法，而是使用传统的机器学习中的序列标注方法。首先，他们认为用户的query可以根据是否有显性的意图词分为两类（这一部分主要根据实体词匹配算法得到）。对于有显性意图词语的query，采用**基于规则**的处理的方法进行标注；剩下的部分采用**基于模型**的方法，具体的模型方法分为5步：\n\n1. 对query进行分词和词性标注（POS）。\n\n2. 寻找槽边界：先对处理后的query使用character embedding + word embedding; 根据BILOU原则，使用CRF对其进行序列标注。\n\n3. 槽分类：根据槽边界检测结果的character embedding + word embedding以及词性标注结果POS，通过逻辑回归的方式（Logistic Regression）进行分类。\n\n4. 槽修正：若槽类别预测错误，则根据词之间的相似性寻找真实槽类别中的所有的值与之进行相似度比较，进而修正结果。\n\n5. 意图分类：使用**XGBoost**的方法，根据word embedding，query长度，槽类别进行意图分类。\n\n注：由于训练样本比较少，针对模型预测错误的数据，他们根据比较query与Sogou语音中最匹配的进行替换，最终针对意图分类增加了500个数据，槽填充增加了1000个数据。\n\n**结果**：这个模型在两个评估方法的结果最终为96.11%，94.49%。\n\n## 英文数据集\n\n### [Frame](https://datasets.maluuba.com/Frames/dl)\n\n#### 数据描述 [4]\n这个数据集主要针对航班和酒店预订，来源于基于Wizard-of-Oz(WOz)设定的人机对话的过程（实际上是一个人假扮机器）。其中包括 **1369** 个对话, 总共有 **19986** 轮。\n\n**数据格式**\n每一次叙述都包含 'author', 'text', 'labels', 'timestamp', 'frames'('frame id', 'frame parent id', 'requests, binary questions, compare requests', 'info'), 'db'字段。其中 'labels'记录当前的active_frame以及对话过程中的Act(包括act名称以及对应的slot类型和值)， 'info'字段主要为了标注对于槽位值是否为否定的。\n\n**Act类型**：inform, offer, request, switch frame, suggest, no result, thankyou, goodbye.....\n\n\n#### 评估方法\n微软在提出这个数据集的同时，也定义了一个任务Frame Tracking，这个任务与State Tracking不同的是，它可以同时追踪一个frame与之前几轮相关的frame，以及由一个frame转变到多个frame，例如用户要求系统可以推荐4个符合条件的旅行，如下图所示：\n<div align=center>\n\t<img src=\"/images/intent_frame.png\" width = \"300\" align=center/>\n</div>\n\n这个任务就是需要预测是否有新的frame生成。如果有，则预测其目的Act，限制条件Ref Labels以及之前相关的Frame ID，如果预测结果完全匹配，则认为预测正确，最后计算准确度。同时计算总的预测有新的frame生成的叙述个数，计算其识别新frame生成的准确度。\n\n#### 主要算法\n\n##### Baseline [4]\n由下图可知模型结构，针对叙述中的每个词，将其表示为trigrams的形式，然后通过一个embedding层，tanh激活层。针对Act分类和Slot分类，分别用一个双向的GRU实现，输入为每个词在激活层的输出。最后经由一个softmax分类层得到最终的类别。\n<div align=center>\n\t<img src=\"/images/intent_frame_baseline.png\" width = \"300\" align=center/>\n</div>\n\n**结果**：这个模型在两个评估方法的结果最终为：frame识别准确度0.24 ± 0.02, frame新建识别准确度为0.49 ± 0.03。\n\n##### Frame Tracking Model for Memory-Enhanced Dialogue Systems [5]\n微软的团队随后提出了一个新的模型来处理这个问题。\n\n###### 输入预处理\n\n- Token Encoding：每个词用trigrams的形式表示。如：“hello” -> #he, hel, ell, llo, lo#。构建trigrams词典D-T，每个词都表示为（Trigrams ID）。 \n\n- 用户叙述：将叙述中的每个词用trigrams的形式表示，这些trigrams经过一个embedding层，输出的向量的和来表示这个token，再经过一个 Bidirectional GRU，将所有的隐层状态堆叠起来来表示此轮的叙述。\n\n- Frame：每个frame由槽类型Slot和槽值Value组成，与trigrams类似，分别构建槽类型词典D-S和槽值词典D-V。即，每个frame表示为（Slot ID, Token ID）。\n\n- Act：每个act由行动类型Act，槽类型Slot和槽值Value组成。即，每个act表示为（Act ID, Slot ID, Token ID）。\n\n\n###### 模型输入\n\n- 当前轮之前所有的frames （Slot ID, Trigrams ID）\n\n- 叙述 （Trigrams ID）\n\n- 当前轮对应的行动Act （Act ID, Slot ID, Trigrams ID）\n\n###### 模型结构\n\n<div align=center>\n\t<img src=\"/images/intent_frame_model.png\" width = \"400\" align=center/>\n</div>\n\n1. 对于frames，（Slot, Token）经过一个GRU，将隐层其映射为一个256维的向量，所有的隐层堆叠起来表示最终的frames，\\\\(m_f\\\\) （|F| \\* 256）；对于act，将（Act, Slot, Token）输入一个 Bidirectional GRU，将隐层以及叙述embedding连接起来，并将其映射为 \\\\(m_{asv}\\\\) （N \\* 256, N为act的数量）来表示acts；\n\n2. 通过计算 \\\\(m_f\\\\) 和 \\\\(m_{asv}\\\\) 的点乘的结果 \\\\(S_m\\\\) （N \\* |F|）来表示act和frame之间的相似性，也可以看做基于frame的一个多项分布。特别地，他们还事先根据act中的槽值与frame之间的槽值的相似性计算了act与frame之间的相似性 \\\\(S_L\\\\) 。最终，根据两者的线性组合来表示act与frame之间的相似性 S。\n\n3. 在用户新输入一个（act, slot, value）表示时，根据这个相似矩阵可以得到一个多项分布\\\\(p_{asv, f}\\\\) ，从而得到与之相关的frames，从而也就得到了他们实验的衡量指标之一，基于槽分类slot的frame追踪。\n\n4. 另外，对于每一个（act，frame）对，他们会根据输入的act, 以及用户的叙述经过两个全连接层得到最终的 \\\\(p_{a, f}\\\\) ，从而也就得到了他们实验的另一个衡量指标，基于行动act的frame追踪。\n\n**注**：这里没有详细介绍实验的一些完善trick，如模型图中的\\\\(g_c\\\\)， \\\\(g_n\\\\)， \\\\(h_d\\\\)， \\\\(h_c\\\\)，详情请看论文。\n\n**结果**：这个模型在基于槽分类的准确度为76.43 ± 4.49，基于行动Act分类的准确度为95.66 ± 2.34。\n\n\n### [DSTC](https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/) (Dialog State Tracking Challenge) [6, 7]\n\n#### 数据描述\nDSTC 是针对一系列的对话数据，完成对话跟踪的任务。也就是针对每一个数据集，意在可以根据之前的状态来预测新的对话的状态。目前DSTC数据已经更新到DSCT6，下面将简单介绍各个版本的数据。\n- DSTC 1\n 这个数据集包括城市BUS的预定电话中的对话数据。**12963**轮训练数据，**2485**轮测试数据。\n\n- DSTC 2&3\n 在DSTC 1的基础上，增加了关于餐厅，旅游信息等等相关的对话。其中DSTC2包括**2218**轮训练数据，**1117**轮测试数据；DSTC3包括**3235**轮训练数据，**2275**轮测试数据。数据中的`semantics`字段会对对话中的槽slot和目的act标注。下面是一个数据样例：\n ```bash\n DSTC2 and DSTC3 (Training Set)\n SYS: Which part of town?\n USR: The north uh area\n SYS: Which part of town?\n USR: A cheap place in the north\n SYS: Clown cafe is a cheap restaurant in the north part of town. USR: Do you have any others like that?\n SYS: Galleria is another cheap restaurant in the north. USR: What is their phone number and address?\n ```\n\n- DSTC 4 \n 这个数据集是人与人之间关于旅游信息的对话数据，其中有一个子任务Spoken language understanding，意在给每个叙述中的目的acts和语义槽slots打标签。挑战赛总共收到了5个提交模型[7]，其中最好的结果的F1值约为0.52。其中三个模型分别为：\n - SVM分类模型\n  输入：叙述的unigrams, bigrams, trigrams，标签（标注当前叙述与上一个叙述是否为同一个人）\n - 逻辑回归模型 \n  输入：同上。\n - 随机森林模型\n  输入：问题数目，标签（标注当前叙述与上一个叙述是否为同一个人），标签（标注当前叙述与上上一个叙述是否为同一个人），标签（标注这个人是导游还是旅客）\n\n- DSTC 5\n 这个数据集针对跨语言测量，也就是训练集为英语数据，测试集为中文数据。\n\n- DSTC 6\n 这个数据集关注在多轮对话，其任务包括端到端的目标导向的对话学习，端到端会话建模，以及对话故障检测。\n\n#### 评估方法 （DSTC2 & 3）\n- 准确度：正确预测的轮数占数据总轮数的百分数。\n- L2距离：向量1为正确预测的轮标为1，其余为0组成的向量；向量2为根据模型得到的每一个的概率值组成的向量，计算向量之间的距离。\n\n#### 主要算法\n这里我们主要关注在DSTC3上的四个模型。\n\n##### 马尔科夫判别模型 [8]\n<!-- team7 -->\n这是来自中科院声学与语言理解研究所的一个模型。为了能够支持未知的领域，因此这篇文章将通过假设每一轮的可能的域来动态的更新分类的类别。\n$$ Y_t^s = Y_{t-1}^s + H_t^s$$，其中\\\\(H_t^s\\\\)是在t轮对于槽类型s的假设的集合。\n\n另外，也是本文中比较新的一点是**马尔科夫判别模型**，也就是将生成模型和判别模型相结合：\n\n生成模型： \\\\(P(S_t) = k \\sum_{S_{t-1} \\in S} P(O^t | S_t) P(S_t | S_{t-1}) P(S_t) \\\\)\n\n判别模型： \\\\(P(S_t | O_1^t) = f(O_1^t)\\\\)\n\n马尔科夫判别模型：\\\\((P(S_t | O_1^t) = \\sum_{S_{t-1} \\in S} P(S_t | O_1^t, S_{t-1}) P( S_{t-1} | O_1^{t-1})\\\\)\n\n在训练过程中，由于当前叙述之前所有的标签都是已知的，而预测过程中之前的都是预测的结果，这会导致训练的模型会过度依赖状态转移矩阵，这个问题称作**标签过耦合**问题。为了解决这个问题，他们设计了一个2步训练法：\n\n- 第一步：训练一个传统的判别模型。\n\n- 第二部：在第一步的基础上训练状态转移特征。\n\n这样第一步预测的错误会在一定程度上解耦相邻的状态直接的联系。最终这个模型在准确度和L2距离的结果分别为0.576，0.652。 \n\n##### 循环神经网络 [9] \n<!-- team 3 -->\n这个模型的注重点在于模型对扩展域的自适应性的问题（即训练数据中不存在的槽类型即槽值）。其中，系统将用户叙述中的槽类型和槽值分别用<slot\\>和<value\\>来替代。由于对于每个叙述表示的都是在不同的槽类型和槽值之间的概率分布，因此若一个新的叙述的概率分布与系统的已知的叙述中的概率分布类似，则可以认为两者具有类似的的槽类型和槽值的关系。\n\n<div align=center>\n\t<img src=\"/images/intent_dstc_rnn.png\" width = \"400\" align=center/>\n</div>\n\n通过上图的过程，我们可以得出 \"Jamaican food\"标记为 \"s=food and v=jamaican\"，若新的叙述为 \"The Girton area\" 其替换为<slot\\>和<value\\>的概率分布与前者类似，因此可以得出 \"s=area and v=girton\"。最终这个模型在准确度和L2距离的结果分别为0.646，0.534。\n\n##### 基于规则的模型 [10] \n<!-- team 5 -->\n这篇文章设定了很多推理规则，并将规则看做是满足某些线性约束的特殊类型的多项式函数，**马尔可夫贝叶斯多项式 (Markov Bayesian Polynomial, MBP)**。在某些假设下，这个模型的求解过程可被视为整数线性规划问题 (Integer Linear Programming, ILP)，实验证明其具有很好的泛化能力。最终这个模型在准确度和L2距离的结果分别为0.610，0.556。 \n\n\n##### 知识驱动的基于规则的模型 [11] \n<!-- team 4 -->\n这篇文章认为目前的语言理解模型无法识别用户不关注的点，以及一些易产生歧义的信息，因此他们提出了一种基于知识的方法。对于每轮叙述，会基于机器的上一个动作act，用户的acts以及之前的act的概率分布猜想生成新的用户目标的概率分布猜想，类似于一个演绎推理的过程。最终这个模型在准确度和L2距离的结果分别为0.630，0.627。\n\n\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n\n\n\n\n\n[1] Overview of the NLPCC 2018 Shared Task: Spoken Language Understanding in Task-Oriented Dialog Systems\n[2] Learning Dialogue History for Spoken Language Understanding.\n[3] The Sogou Spoken Language Understanding System for the NLPCC 2018 Evaluation.\n[4] Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems.\n[5] A Frame Tracking Model for Memory-Enhanced Dialogue Systems.\n[6] The Dialog State Tracking Challenge Series: A Review, Learning End-To-End Goal-oriented Dialog.\n[7] Adobe-MIT submission to the DSTC 4 Spoken Language Understanding pilot task.\n[8] Markovian discriminative modeling for cross-domain dialog state tracking. \n[9] Robust Dialog State Tracking Using Delexicalised Recurrent Neural Networks and Unsupervised Adaptation.\n[10] A generalized rule based tracker for dialogue state tracking. \n[11] Knowledge-based dialog state tracking.\n\n","source":"_posts/intent_slot.md","raw":"---\ntitle: Review on Intent Classification and Slot Filling\ndate: 2018-11-02 10:41:02\ntags: Research\n---\n\n自然语言理解（Natural Language Understanding, NLU）是NLP领域的一个分支，在自然语言理解的过程中，首先就是对意图（Intent）分类，然后接着对槽位（Slot）填充。\n\n<!--more-->\n\n意图分类时一个典型的文本分类的问题，常用的方法如下：\n- 基于规则的方法\n 用户人工定义一些匹配规则进行分类。\n- 机器学习的方法\n SVM, Decision Tree等等。\n- 深度学习的方法\n 目前更加推崇使用 End-to-End 的网络进行分类。\n\n最近收集了一些关于意图分类以及槽填充的相关的数据集以及对应的测试指标。\n\n## 中文数据集\n\n### [NLPCC 2018 Task4](http://tcci.ccf.org.cn/conference/2018/taskdata.php) - Spoken Language Understanding in Task-Oriented Dialogue Systems\n\n#### 数据描述 [1]\n这个数据集来源于某车载产品的真实日志数据，主要涉及音乐，导航以及打电话等等领域，11种意图以及15种槽值类型。其中包括 **5.8K** 次会话，总共有 **26K** 次叙述（Utterance）。特别地，这个数据集仅仅包含了用户的输入（没有系统的回复），并且针对错误的槽值进行了修正，如将“什话”修正为“神话”。\n\n - 训练集：4705次会话, 21352次叙述。\n - 验证集：1177次会话, 5350次叙述。 （训练集：验证集 约 4:1）\n\n数据格式\n``` bash\nsession ID    用户query              意图                       语义槽标注\n    1           打电话\t   phone_call.make_a_phone_call\t        打电话\n    1\t      我想听美观\t        music.play\t          我想听<song>美观</song>\n    1\t      我想听什话\t        music.play\t          我想听<song>什话||神话</song>\n```\n\n#### 评估方法\n这个比赛主要有两个评估方法:\n\n- 意图分类，评估方法为F1值，具体的计算方法如下：\n<div align=center>\n\t<img src=\"/images/intent_f1.png\" width = \"500\"/>\n</div>\n\n- 意图分类以及槽填充，评估方法是准确度。即意图分类以及所有的槽位都完全正确。\n\n#### 主要算法\n总共有16个队伍参加了这个比赛，但是只有两个队伍开源了他们的方法，分别是HLSTM-SLU模型和Sogou团队的模型。具体结果如下：\n<div align=center>\n\t<img src=\"/images/intent_results.png\" width = \"500\" align=center/>\n</div>\n\n##### HLSTM-SLU [2]\n这个可以看做是深度学习的方法和传统的机器学习方法相结合。模型结构如下：\n<div align=center>\n\t<img src=\"/images/intent_hlstm.png\" width = \"500\" align=center/>\n</div>\n\n这个模型主要由三个LSTM组成，两个双向LSTM处理输入和输出，一个单向LSTM处理一个会话中的多个叙述。\n\n- 输入Bi-LSTM\n 输入：Character Embedding + POS + Domain \n 其中POS表示对每个字进行词性标注，并用类似于BI的方法进行编码；Domain表示不同领域的词，也用BI的方法进行编码，具体实例如下：\n\n<div align=center>\n\t<img src=\"/images/intent_input.png\" width = \"500\" align=center/>\n</div>\n\n- Session LSTM\n 输入：一次对话中的每轮的描述经过输入Bi-LSTM的输出经过最大池化之后的结果。\n 输出：**意图的类别**\n\n- 输出Bi-LSTM\n 输入：Session LSTM + 输入Bi-LSTM\n 输出：**槽位标注**\n\n注：并没有直接使用LSTM的结果作为最终的结果，而是根据 **CRF** 预测最优的序列。\n\n**Trick**: 使用 **over sampling** 解决意图类别中的样本不均衡的问题，并在过程中使用规则识别了一部分小样本的意图。\n\n**结果**：这个模型在两个评估方法的结果最终为94.19%，90.84%。\n\n##### Sogou [3]\n这个模型没有使用深度学习的方法，而是使用传统的机器学习中的序列标注方法。首先，他们认为用户的query可以根据是否有显性的意图词分为两类（这一部分主要根据实体词匹配算法得到）。对于有显性意图词语的query，采用**基于规则**的处理的方法进行标注；剩下的部分采用**基于模型**的方法，具体的模型方法分为5步：\n\n1. 对query进行分词和词性标注（POS）。\n\n2. 寻找槽边界：先对处理后的query使用character embedding + word embedding; 根据BILOU原则，使用CRF对其进行序列标注。\n\n3. 槽分类：根据槽边界检测结果的character embedding + word embedding以及词性标注结果POS，通过逻辑回归的方式（Logistic Regression）进行分类。\n\n4. 槽修正：若槽类别预测错误，则根据词之间的相似性寻找真实槽类别中的所有的值与之进行相似度比较，进而修正结果。\n\n5. 意图分类：使用**XGBoost**的方法，根据word embedding，query长度，槽类别进行意图分类。\n\n注：由于训练样本比较少，针对模型预测错误的数据，他们根据比较query与Sogou语音中最匹配的进行替换，最终针对意图分类增加了500个数据，槽填充增加了1000个数据。\n\n**结果**：这个模型在两个评估方法的结果最终为96.11%，94.49%。\n\n## 英文数据集\n\n### [Frame](https://datasets.maluuba.com/Frames/dl)\n\n#### 数据描述 [4]\n这个数据集主要针对航班和酒店预订，来源于基于Wizard-of-Oz(WOz)设定的人机对话的过程（实际上是一个人假扮机器）。其中包括 **1369** 个对话, 总共有 **19986** 轮。\n\n**数据格式**\n每一次叙述都包含 'author', 'text', 'labels', 'timestamp', 'frames'('frame id', 'frame parent id', 'requests, binary questions, compare requests', 'info'), 'db'字段。其中 'labels'记录当前的active_frame以及对话过程中的Act(包括act名称以及对应的slot类型和值)， 'info'字段主要为了标注对于槽位值是否为否定的。\n\n**Act类型**：inform, offer, request, switch frame, suggest, no result, thankyou, goodbye.....\n\n\n#### 评估方法\n微软在提出这个数据集的同时，也定义了一个任务Frame Tracking，这个任务与State Tracking不同的是，它可以同时追踪一个frame与之前几轮相关的frame，以及由一个frame转变到多个frame，例如用户要求系统可以推荐4个符合条件的旅行，如下图所示：\n<div align=center>\n\t<img src=\"/images/intent_frame.png\" width = \"300\" align=center/>\n</div>\n\n这个任务就是需要预测是否有新的frame生成。如果有，则预测其目的Act，限制条件Ref Labels以及之前相关的Frame ID，如果预测结果完全匹配，则认为预测正确，最后计算准确度。同时计算总的预测有新的frame生成的叙述个数，计算其识别新frame生成的准确度。\n\n#### 主要算法\n\n##### Baseline [4]\n由下图可知模型结构，针对叙述中的每个词，将其表示为trigrams的形式，然后通过一个embedding层，tanh激活层。针对Act分类和Slot分类，分别用一个双向的GRU实现，输入为每个词在激活层的输出。最后经由一个softmax分类层得到最终的类别。\n<div align=center>\n\t<img src=\"/images/intent_frame_baseline.png\" width = \"300\" align=center/>\n</div>\n\n**结果**：这个模型在两个评估方法的结果最终为：frame识别准确度0.24 ± 0.02, frame新建识别准确度为0.49 ± 0.03。\n\n##### Frame Tracking Model for Memory-Enhanced Dialogue Systems [5]\n微软的团队随后提出了一个新的模型来处理这个问题。\n\n###### 输入预处理\n\n- Token Encoding：每个词用trigrams的形式表示。如：“hello” -> #he, hel, ell, llo, lo#。构建trigrams词典D-T，每个词都表示为（Trigrams ID）。 \n\n- 用户叙述：将叙述中的每个词用trigrams的形式表示，这些trigrams经过一个embedding层，输出的向量的和来表示这个token，再经过一个 Bidirectional GRU，将所有的隐层状态堆叠起来来表示此轮的叙述。\n\n- Frame：每个frame由槽类型Slot和槽值Value组成，与trigrams类似，分别构建槽类型词典D-S和槽值词典D-V。即，每个frame表示为（Slot ID, Token ID）。\n\n- Act：每个act由行动类型Act，槽类型Slot和槽值Value组成。即，每个act表示为（Act ID, Slot ID, Token ID）。\n\n\n###### 模型输入\n\n- 当前轮之前所有的frames （Slot ID, Trigrams ID）\n\n- 叙述 （Trigrams ID）\n\n- 当前轮对应的行动Act （Act ID, Slot ID, Trigrams ID）\n\n###### 模型结构\n\n<div align=center>\n\t<img src=\"/images/intent_frame_model.png\" width = \"400\" align=center/>\n</div>\n\n1. 对于frames，（Slot, Token）经过一个GRU，将隐层其映射为一个256维的向量，所有的隐层堆叠起来表示最终的frames，\\\\(m_f\\\\) （|F| \\* 256）；对于act，将（Act, Slot, Token）输入一个 Bidirectional GRU，将隐层以及叙述embedding连接起来，并将其映射为 \\\\(m_{asv}\\\\) （N \\* 256, N为act的数量）来表示acts；\n\n2. 通过计算 \\\\(m_f\\\\) 和 \\\\(m_{asv}\\\\) 的点乘的结果 \\\\(S_m\\\\) （N \\* |F|）来表示act和frame之间的相似性，也可以看做基于frame的一个多项分布。特别地，他们还事先根据act中的槽值与frame之间的槽值的相似性计算了act与frame之间的相似性 \\\\(S_L\\\\) 。最终，根据两者的线性组合来表示act与frame之间的相似性 S。\n\n3. 在用户新输入一个（act, slot, value）表示时，根据这个相似矩阵可以得到一个多项分布\\\\(p_{asv, f}\\\\) ，从而得到与之相关的frames，从而也就得到了他们实验的衡量指标之一，基于槽分类slot的frame追踪。\n\n4. 另外，对于每一个（act，frame）对，他们会根据输入的act, 以及用户的叙述经过两个全连接层得到最终的 \\\\(p_{a, f}\\\\) ，从而也就得到了他们实验的另一个衡量指标，基于行动act的frame追踪。\n\n**注**：这里没有详细介绍实验的一些完善trick，如模型图中的\\\\(g_c\\\\)， \\\\(g_n\\\\)， \\\\(h_d\\\\)， \\\\(h_c\\\\)，详情请看论文。\n\n**结果**：这个模型在基于槽分类的准确度为76.43 ± 4.49，基于行动Act分类的准确度为95.66 ± 2.34。\n\n\n### [DSTC](https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/) (Dialog State Tracking Challenge) [6, 7]\n\n#### 数据描述\nDSTC 是针对一系列的对话数据，完成对话跟踪的任务。也就是针对每一个数据集，意在可以根据之前的状态来预测新的对话的状态。目前DSTC数据已经更新到DSCT6，下面将简单介绍各个版本的数据。\n- DSTC 1\n 这个数据集包括城市BUS的预定电话中的对话数据。**12963**轮训练数据，**2485**轮测试数据。\n\n- DSTC 2&3\n 在DSTC 1的基础上，增加了关于餐厅，旅游信息等等相关的对话。其中DSTC2包括**2218**轮训练数据，**1117**轮测试数据；DSTC3包括**3235**轮训练数据，**2275**轮测试数据。数据中的`semantics`字段会对对话中的槽slot和目的act标注。下面是一个数据样例：\n ```bash\n DSTC2 and DSTC3 (Training Set)\n SYS: Which part of town?\n USR: The north uh area\n SYS: Which part of town?\n USR: A cheap place in the north\n SYS: Clown cafe is a cheap restaurant in the north part of town. USR: Do you have any others like that?\n SYS: Galleria is another cheap restaurant in the north. USR: What is their phone number and address?\n ```\n\n- DSTC 4 \n 这个数据集是人与人之间关于旅游信息的对话数据，其中有一个子任务Spoken language understanding，意在给每个叙述中的目的acts和语义槽slots打标签。挑战赛总共收到了5个提交模型[7]，其中最好的结果的F1值约为0.52。其中三个模型分别为：\n - SVM分类模型\n  输入：叙述的unigrams, bigrams, trigrams，标签（标注当前叙述与上一个叙述是否为同一个人）\n - 逻辑回归模型 \n  输入：同上。\n - 随机森林模型\n  输入：问题数目，标签（标注当前叙述与上一个叙述是否为同一个人），标签（标注当前叙述与上上一个叙述是否为同一个人），标签（标注这个人是导游还是旅客）\n\n- DSTC 5\n 这个数据集针对跨语言测量，也就是训练集为英语数据，测试集为中文数据。\n\n- DSTC 6\n 这个数据集关注在多轮对话，其任务包括端到端的目标导向的对话学习，端到端会话建模，以及对话故障检测。\n\n#### 评估方法 （DSTC2 & 3）\n- 准确度：正确预测的轮数占数据总轮数的百分数。\n- L2距离：向量1为正确预测的轮标为1，其余为0组成的向量；向量2为根据模型得到的每一个的概率值组成的向量，计算向量之间的距离。\n\n#### 主要算法\n这里我们主要关注在DSTC3上的四个模型。\n\n##### 马尔科夫判别模型 [8]\n<!-- team7 -->\n这是来自中科院声学与语言理解研究所的一个模型。为了能够支持未知的领域，因此这篇文章将通过假设每一轮的可能的域来动态的更新分类的类别。\n$$ Y_t^s = Y_{t-1}^s + H_t^s$$，其中\\\\(H_t^s\\\\)是在t轮对于槽类型s的假设的集合。\n\n另外，也是本文中比较新的一点是**马尔科夫判别模型**，也就是将生成模型和判别模型相结合：\n\n生成模型： \\\\(P(S_t) = k \\sum_{S_{t-1} \\in S} P(O^t | S_t) P(S_t | S_{t-1}) P(S_t) \\\\)\n\n判别模型： \\\\(P(S_t | O_1^t) = f(O_1^t)\\\\)\n\n马尔科夫判别模型：\\\\((P(S_t | O_1^t) = \\sum_{S_{t-1} \\in S} P(S_t | O_1^t, S_{t-1}) P( S_{t-1} | O_1^{t-1})\\\\)\n\n在训练过程中，由于当前叙述之前所有的标签都是已知的，而预测过程中之前的都是预测的结果，这会导致训练的模型会过度依赖状态转移矩阵，这个问题称作**标签过耦合**问题。为了解决这个问题，他们设计了一个2步训练法：\n\n- 第一步：训练一个传统的判别模型。\n\n- 第二部：在第一步的基础上训练状态转移特征。\n\n这样第一步预测的错误会在一定程度上解耦相邻的状态直接的联系。最终这个模型在准确度和L2距离的结果分别为0.576，0.652。 \n\n##### 循环神经网络 [9] \n<!-- team 3 -->\n这个模型的注重点在于模型对扩展域的自适应性的问题（即训练数据中不存在的槽类型即槽值）。其中，系统将用户叙述中的槽类型和槽值分别用<slot\\>和<value\\>来替代。由于对于每个叙述表示的都是在不同的槽类型和槽值之间的概率分布，因此若一个新的叙述的概率分布与系统的已知的叙述中的概率分布类似，则可以认为两者具有类似的的槽类型和槽值的关系。\n\n<div align=center>\n\t<img src=\"/images/intent_dstc_rnn.png\" width = \"400\" align=center/>\n</div>\n\n通过上图的过程，我们可以得出 \"Jamaican food\"标记为 \"s=food and v=jamaican\"，若新的叙述为 \"The Girton area\" 其替换为<slot\\>和<value\\>的概率分布与前者类似，因此可以得出 \"s=area and v=girton\"。最终这个模型在准确度和L2距离的结果分别为0.646，0.534。\n\n##### 基于规则的模型 [10] \n<!-- team 5 -->\n这篇文章设定了很多推理规则，并将规则看做是满足某些线性约束的特殊类型的多项式函数，**马尔可夫贝叶斯多项式 (Markov Bayesian Polynomial, MBP)**。在某些假设下，这个模型的求解过程可被视为整数线性规划问题 (Integer Linear Programming, ILP)，实验证明其具有很好的泛化能力。最终这个模型在准确度和L2距离的结果分别为0.610，0.556。 \n\n\n##### 知识驱动的基于规则的模型 [11] \n<!-- team 4 -->\n这篇文章认为目前的语言理解模型无法识别用户不关注的点，以及一些易产生歧义的信息，因此他们提出了一种基于知识的方法。对于每轮叙述，会基于机器的上一个动作act，用户的acts以及之前的act的概率分布猜想生成新的用户目标的概率分布猜想，类似于一个演绎推理的过程。最终这个模型在准确度和L2距离的结果分别为0.630，0.627。\n\n\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n\n\n\n\n\n[1] Overview of the NLPCC 2018 Shared Task: Spoken Language Understanding in Task-Oriented Dialog Systems\n[2] Learning Dialogue History for Spoken Language Understanding.\n[3] The Sogou Spoken Language Understanding System for the NLPCC 2018 Evaluation.\n[4] Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems.\n[5] A Frame Tracking Model for Memory-Enhanced Dialogue Systems.\n[6] The Dialog State Tracking Challenge Series: A Review, Learning End-To-End Goal-oriented Dialog.\n[7] Adobe-MIT submission to the DSTC 4 Spoken Language Understanding pilot task.\n[8] Markovian discriminative modeling for cross-domain dialog state tracking. \n[9] Robust Dialog State Tracking Using Delexicalised Recurrent Neural Networks and Unsupervised Adaptation.\n[10] A generalized rule based tracker for dialogue state tracking. \n[11] Knowledge-based dialog state tracking.\n\n","slug":"intent_slot","published":1,"updated":"2018-11-05T10:44:30.288Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo46iqim00031wzmv57fqm29","content":"<p>自然语言理解（Natural Language Understanding, NLU）是NLP领域的一个分支，在自然语言理解的过程中，首先就是对意图（Intent）分类，然后接着对槽位（Slot）填充。</p>\n<a id=\"more\"></a>\n<p>意图分类时一个典型的文本分类的问题，常用的方法如下：</p>\n<ul>\n<li>基于规则的方法<br>用户人工定义一些匹配规则进行分类。</li>\n<li>机器学习的方法<br>SVM, Decision Tree等等。</li>\n<li>深度学习的方法<br>目前更加推崇使用 End-to-End 的网络进行分类。</li>\n</ul>\n<p>最近收集了一些关于意图分类以及槽填充的相关的数据集以及对应的测试指标。</p>\n<h2 id=\"中文数据集\"><a href=\"#中文数据集\" class=\"headerlink\" title=\"中文数据集\"></a>中文数据集</h2><h3 id=\"NLPCC-2018-Task4-Spoken-Language-Understanding-in-Task-Oriented-Dialogue-Systems\"><a href=\"#NLPCC-2018-Task4-Spoken-Language-Understanding-in-Task-Oriented-Dialogue-Systems\" class=\"headerlink\" title=\"NLPCC 2018 Task4 - Spoken Language Understanding in Task-Oriented Dialogue Systems\"></a><a href=\"http://tcci.ccf.org.cn/conference/2018/taskdata.php\" target=\"_blank\" rel=\"noopener\">NLPCC 2018 Task4</a> - Spoken Language Understanding in Task-Oriented Dialogue Systems</h3><h4 id=\"数据描述-1\"><a href=\"#数据描述-1\" class=\"headerlink\" title=\"数据描述 [1]\"></a>数据描述 [1]</h4><p>这个数据集来源于某车载产品的真实日志数据，主要涉及音乐，导航以及打电话等等领域，11种意图以及15种槽值类型。其中包括 <strong>5.8K</strong> 次会话，总共有 <strong>26K</strong> 次叙述（Utterance）。特别地，这个数据集仅仅包含了用户的输入（没有系统的回复），并且针对错误的槽值进行了修正，如将“什话”修正为“神话”。</p>\n<ul>\n<li>训练集：4705次会话, 21352次叙述。</li>\n<li>验证集：1177次会话, 5350次叙述。 （训练集：验证集 约 4:1）</li>\n</ul>\n<p>数据格式<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">session ID    用户query              意图                       语义槽标注</span><br><span class=\"line\">    1           打电话\t   phone_call.make_a_phone_call\t        打电话</span><br><span class=\"line\">    1\t      我想听美观\t        music.play\t          我想听&lt;song&gt;美观&lt;/song&gt;</span><br><span class=\"line\">    1\t      我想听什话\t        music.play\t          我想听&lt;song&gt;什话||神话&lt;/song&gt;</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"评估方法\"><a href=\"#评估方法\" class=\"headerlink\" title=\"评估方法\"></a>评估方法</h4><p>这个比赛主要有两个评估方法:</p>\n<ul>\n<li><p>意图分类，评估方法为F1值，具体的计算方法如下：</p>\n<div align=\"center\"><br>  <img src=\"/images/intent_f1.png\" width=\"500\"><br></div>\n</li>\n<li><p>意图分类以及槽填充，评估方法是准确度。即意图分类以及所有的槽位都完全正确。</p>\n</li>\n</ul>\n<h4 id=\"主要算法\"><a href=\"#主要算法\" class=\"headerlink\" title=\"主要算法\"></a>主要算法</h4><p>总共有16个队伍参加了这个比赛，但是只有两个队伍开源了他们的方法，分别是HLSTM-SLU模型和Sogou团队的模型。具体结果如下：</p>\n<div align=\"center\"><br>    <img src=\"/images/intent_results.png\" width=\"500\" align=\"center/\"><br></div>\n\n<h5 id=\"HLSTM-SLU-2\"><a href=\"#HLSTM-SLU-2\" class=\"headerlink\" title=\"HLSTM-SLU [2]\"></a>HLSTM-SLU [2]</h5><p>这个可以看做是深度学习的方法和传统的机器学习方法相结合。模型结构如下：</p>\n<div align=\"center\"><br>    <img src=\"/images/intent_hlstm.png\" width=\"500\" align=\"center/\"><br></div>\n\n<p>这个模型主要由三个LSTM组成，两个双向LSTM处理输入和输出，一个单向LSTM处理一个会话中的多个叙述。</p>\n<ul>\n<li>输入Bi-LSTM<br>输入：Character Embedding + POS + Domain<br>其中POS表示对每个字进行词性标注，并用类似于BI的方法进行编码；Domain表示不同领域的词，也用BI的方法进行编码，具体实例如下：</li>\n</ul>\n<div align=\"center\"><br>    <img src=\"/images/intent_input.png\" width=\"500\" align=\"center/\"><br></div>\n\n<ul>\n<li><p>Session LSTM<br>输入：一次对话中的每轮的描述经过输入Bi-LSTM的输出经过最大池化之后的结果。<br>输出：<strong>意图的类别</strong></p>\n</li>\n<li><p>输出Bi-LSTM<br>输入：Session LSTM + 输入Bi-LSTM<br>输出：<strong>槽位标注</strong></p>\n</li>\n</ul>\n<p>注：并没有直接使用LSTM的结果作为最终的结果，而是根据 <strong>CRF</strong> 预测最优的序列。</p>\n<p><strong>Trick</strong>: 使用 <strong>over sampling</strong> 解决意图类别中的样本不均衡的问题，并在过程中使用规则识别了一部分小样本的意图。</p>\n<p><strong>结果</strong>：这个模型在两个评估方法的结果最终为94.19%，90.84%。</p>\n<h5 id=\"Sogou-3\"><a href=\"#Sogou-3\" class=\"headerlink\" title=\"Sogou [3]\"></a>Sogou [3]</h5><p>这个模型没有使用深度学习的方法，而是使用传统的机器学习中的序列标注方法。首先，他们认为用户的query可以根据是否有显性的意图词分为两类（这一部分主要根据实体词匹配算法得到）。对于有显性意图词语的query，采用<strong>基于规则</strong>的处理的方法进行标注；剩下的部分采用<strong>基于模型</strong>的方法，具体的模型方法分为5步：</p>\n<ol>\n<li><p>对query进行分词和词性标注（POS）。</p>\n</li>\n<li><p>寻找槽边界：先对处理后的query使用character embedding + word embedding; 根据BILOU原则，使用CRF对其进行序列标注。</p>\n</li>\n<li><p>槽分类：根据槽边界检测结果的character embedding + word embedding以及词性标注结果POS，通过逻辑回归的方式（Logistic Regression）进行分类。</p>\n</li>\n<li><p>槽修正：若槽类别预测错误，则根据词之间的相似性寻找真实槽类别中的所有的值与之进行相似度比较，进而修正结果。</p>\n</li>\n<li><p>意图分类：使用<strong>XGBoost</strong>的方法，根据word embedding，query长度，槽类别进行意图分类。</p>\n</li>\n</ol>\n<p>注：由于训练样本比较少，针对模型预测错误的数据，他们根据比较query与Sogou语音中最匹配的进行替换，最终针对意图分类增加了500个数据，槽填充增加了1000个数据。</p>\n<p><strong>结果</strong>：这个模型在两个评估方法的结果最终为96.11%，94.49%。</p>\n<h2 id=\"英文数据集\"><a href=\"#英文数据集\" class=\"headerlink\" title=\"英文数据集\"></a>英文数据集</h2><h3 id=\"Frame\"><a href=\"#Frame\" class=\"headerlink\" title=\"Frame\"></a><a href=\"https://datasets.maluuba.com/Frames/dl\" target=\"_blank\" rel=\"noopener\">Frame</a></h3><h4 id=\"数据描述-4\"><a href=\"#数据描述-4\" class=\"headerlink\" title=\"数据描述 [4]\"></a>数据描述 [4]</h4><p>这个数据集主要针对航班和酒店预订，来源于基于Wizard-of-Oz(WOz)设定的人机对话的过程（实际上是一个人假扮机器）。其中包括 <strong>1369</strong> 个对话, 总共有 <strong>19986</strong> 轮。</p>\n<p><strong>数据格式</strong><br>每一次叙述都包含 ‘author’, ‘text’, ‘labels’, ‘timestamp’, ‘frames’(‘frame id’, ‘frame parent id’, ‘requests, binary questions, compare requests’, ‘info’), ‘db’字段。其中 ‘labels’记录当前的active_frame以及对话过程中的Act(包括act名称以及对应的slot类型和值)， ‘info’字段主要为了标注对于槽位值是否为否定的。</p>\n<p><strong>Act类型</strong>：inform, offer, request, switch frame, suggest, no result, thankyou, goodbye…..</p>\n<h4 id=\"评估方法-1\"><a href=\"#评估方法-1\" class=\"headerlink\" title=\"评估方法\"></a>评估方法</h4><p>微软在提出这个数据集的同时，也定义了一个任务Frame Tracking，这个任务与State Tracking不同的是，它可以同时追踪一个frame与之前几轮相关的frame，以及由一个frame转变到多个frame，例如用户要求系统可以推荐4个符合条件的旅行，如下图所示：</p>\n<div align=\"center\"><br>    <img src=\"/images/intent_frame.png\" width=\"300\" align=\"center/\"><br></div>\n\n<p>这个任务就是需要预测是否有新的frame生成。如果有，则预测其目的Act，限制条件Ref Labels以及之前相关的Frame ID，如果预测结果完全匹配，则认为预测正确，最后计算准确度。同时计算总的预测有新的frame生成的叙述个数，计算其识别新frame生成的准确度。</p>\n<h4 id=\"主要算法-1\"><a href=\"#主要算法-1\" class=\"headerlink\" title=\"主要算法\"></a>主要算法</h4><h5 id=\"Baseline-4\"><a href=\"#Baseline-4\" class=\"headerlink\" title=\"Baseline [4]\"></a>Baseline [4]</h5><p>由下图可知模型结构，针对叙述中的每个词，将其表示为trigrams的形式，然后通过一个embedding层，tanh激活层。针对Act分类和Slot分类，分别用一个双向的GRU实现，输入为每个词在激活层的输出。最后经由一个softmax分类层得到最终的类别。</p>\n<div align=\"center\"><br>    <img src=\"/images/intent_frame_baseline.png\" width=\"300\" align=\"center/\"><br></div>\n\n<p><strong>结果</strong>：这个模型在两个评估方法的结果最终为：frame识别准确度0.24 ± 0.02, frame新建识别准确度为0.49 ± 0.03。</p>\n<h5 id=\"Frame-Tracking-Model-for-Memory-Enhanced-Dialogue-Systems-5\"><a href=\"#Frame-Tracking-Model-for-Memory-Enhanced-Dialogue-Systems-5\" class=\"headerlink\" title=\"Frame Tracking Model for Memory-Enhanced Dialogue Systems [5]\"></a>Frame Tracking Model for Memory-Enhanced Dialogue Systems [5]</h5><p>微软的团队随后提出了一个新的模型来处理这个问题。</p>\n<h6 id=\"输入预处理\"><a href=\"#输入预处理\" class=\"headerlink\" title=\"输入预处理\"></a>输入预处理</h6><ul>\n<li><p>Token Encoding：每个词用trigrams的形式表示。如：“hello” -&gt; #he, hel, ell, llo, lo#。构建trigrams词典D-T，每个词都表示为（Trigrams ID）。 </p>\n</li>\n<li><p>用户叙述：将叙述中的每个词用trigrams的形式表示，这些trigrams经过一个embedding层，输出的向量的和来表示这个token，再经过一个 Bidirectional GRU，将所有的隐层状态堆叠起来来表示此轮的叙述。</p>\n</li>\n<li><p>Frame：每个frame由槽类型Slot和槽值Value组成，与trigrams类似，分别构建槽类型词典D-S和槽值词典D-V。即，每个frame表示为（Slot ID, Token ID）。</p>\n</li>\n<li><p>Act：每个act由行动类型Act，槽类型Slot和槽值Value组成。即，每个act表示为（Act ID, Slot ID, Token ID）。</p>\n</li>\n</ul>\n<h6 id=\"模型输入\"><a href=\"#模型输入\" class=\"headerlink\" title=\"模型输入\"></a>模型输入</h6><ul>\n<li><p>当前轮之前所有的frames （Slot ID, Trigrams ID）</p>\n</li>\n<li><p>叙述 （Trigrams ID）</p>\n</li>\n<li><p>当前轮对应的行动Act （Act ID, Slot ID, Trigrams ID）</p>\n</li>\n</ul>\n<h6 id=\"模型结构\"><a href=\"#模型结构\" class=\"headerlink\" title=\"模型结构\"></a>模型结构</h6><div align=\"center\"><br>    <img src=\"/images/intent_frame_model.png\" width=\"400\" align=\"center/\"><br></div>\n\n<ol>\n<li><p>对于frames，（Slot, Token）经过一个GRU，将隐层其映射为一个256维的向量，所有的隐层堆叠起来表示最终的frames，\\(m_f\\) （|F| * 256）；对于act，将（Act, Slot, Token）输入一个 Bidirectional GRU，将隐层以及叙述embedding连接起来，并将其映射为 \\(m_{asv}\\) （N * 256, N为act的数量）来表示acts；</p>\n</li>\n<li><p>通过计算 \\(m_f\\) 和 \\(m_{asv}\\) 的点乘的结果 \\(S_m\\) （N * |F|）来表示act和frame之间的相似性，也可以看做基于frame的一个多项分布。特别地，他们还事先根据act中的槽值与frame之间的槽值的相似性计算了act与frame之间的相似性 \\(S_L\\) 。最终，根据两者的线性组合来表示act与frame之间的相似性 S。</p>\n</li>\n<li><p>在用户新输入一个（act, slot, value）表示时，根据这个相似矩阵可以得到一个多项分布\\(p_{asv, f}\\) ，从而得到与之相关的frames，从而也就得到了他们实验的衡量指标之一，基于槽分类slot的frame追踪。</p>\n</li>\n<li><p>另外，对于每一个（act，frame）对，他们会根据输入的act, 以及用户的叙述经过两个全连接层得到最终的 \\(p_{a, f}\\) ，从而也就得到了他们实验的另一个衡量指标，基于行动act的frame追踪。</p>\n</li>\n</ol>\n<p><strong>注</strong>：这里没有详细介绍实验的一些完善trick，如模型图中的\\(g_c\\)， \\(g_n\\)， \\(h_d\\)， \\(h_c\\)，详情请看论文。</p>\n<p><strong>结果</strong>：这个模型在基于槽分类的准确度为76.43 ± 4.49，基于行动Act分类的准确度为95.66 ± 2.34。</p>\n<h3 id=\"DSTC-Dialog-State-Tracking-Challenge-6-7\"><a href=\"#DSTC-Dialog-State-Tracking-Challenge-6-7\" class=\"headerlink\" title=\"DSTC (Dialog State Tracking Challenge) [6, 7]\"></a><a href=\"https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/\" target=\"_blank\" rel=\"noopener\">DSTC</a> (Dialog State Tracking Challenge) [6, 7]</h3><h4 id=\"数据描述\"><a href=\"#数据描述\" class=\"headerlink\" title=\"数据描述\"></a>数据描述</h4><p>DSTC 是针对一系列的对话数据，完成对话跟踪的任务。也就是针对每一个数据集，意在可以根据之前的状态来预测新的对话的状态。目前DSTC数据已经更新到DSCT6，下面将简单介绍各个版本的数据。</p>\n<ul>\n<li><p>DSTC 1<br>这个数据集包括城市BUS的预定电话中的对话数据。<strong>12963</strong>轮训练数据，<strong>2485</strong>轮测试数据。</p>\n</li>\n<li><p>DSTC 2&amp;3<br>在DSTC 1的基础上，增加了关于餐厅，旅游信息等等相关的对话。其中DSTC2包括<strong>2218</strong>轮训练数据，<strong>1117</strong>轮测试数据；DSTC3包括<strong>3235</strong>轮训练数据，<strong>2275</strong>轮测试数据。数据中的<code>semantics</code>字段会对对话中的槽slot和目的act标注。下面是一个数据样例：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DSTC2 and DSTC3 (Training Set)</span><br><span class=\"line\">SYS: Which part of town?</span><br><span class=\"line\">USR: The north uh area</span><br><span class=\"line\">SYS: Which part of town?</span><br><span class=\"line\">USR: A cheap place <span class=\"keyword\">in</span> the north</span><br><span class=\"line\">SYS: Clown cafe is a cheap restaurant <span class=\"keyword\">in</span> the north part of town. USR: Do you have any others like that?</span><br><span class=\"line\">SYS: Galleria is another cheap restaurant <span class=\"keyword\">in</span> the north. USR: What is their phone number and address?</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>DSTC 4<br>这个数据集是人与人之间关于旅游信息的对话数据，其中有一个子任务Spoken language understanding，意在给每个叙述中的目的acts和语义槽slots打标签。挑战赛总共收到了5个提交模型[7]，其中最好的结果的F1值约为0.52。其中三个模型分别为：</p>\n<ul>\n<li>SVM分类模型<br>输入：叙述的unigrams, bigrams, trigrams，标签（标注当前叙述与上一个叙述是否为同一个人）</li>\n<li>逻辑回归模型<br>输入：同上。</li>\n<li>随机森林模型<br>输入：问题数目，标签（标注当前叙述与上一个叙述是否为同一个人），标签（标注当前叙述与上上一个叙述是否为同一个人），标签（标注这个人是导游还是旅客）</li>\n</ul>\n</li>\n<li><p>DSTC 5<br>这个数据集针对跨语言测量，也就是训练集为英语数据，测试集为中文数据。</p>\n</li>\n<li><p>DSTC 6<br>这个数据集关注在多轮对话，其任务包括端到端的目标导向的对话学习，端到端会话建模，以及对话故障检测。</p>\n</li>\n</ul>\n<h4 id=\"评估方法-（DSTC2-amp-3）\"><a href=\"#评估方法-（DSTC2-amp-3）\" class=\"headerlink\" title=\"评估方法 （DSTC2 &amp; 3）\"></a>评估方法 （DSTC2 &amp; 3）</h4><ul>\n<li>准确度：正确预测的轮数占数据总轮数的百分数。</li>\n<li>L2距离：向量1为正确预测的轮标为1，其余为0组成的向量；向量2为根据模型得到的每一个的概率值组成的向量，计算向量之间的距离。</li>\n</ul>\n<h4 id=\"主要算法-2\"><a href=\"#主要算法-2\" class=\"headerlink\" title=\"主要算法\"></a>主要算法</h4><p>这里我们主要关注在DSTC3上的四个模型。</p>\n<h5 id=\"马尔科夫判别模型-8\"><a href=\"#马尔科夫判别模型-8\" class=\"headerlink\" title=\"马尔科夫判别模型 [8]\"></a>马尔科夫判别模型 [8]</h5><!-- team7 -->\n<p>这是来自中科院声学与语言理解研究所的一个模型。为了能够支持未知的领域，因此这篇文章将通过假设每一轮的可能的域来动态的更新分类的类别。<br>$$ Y_t^s = Y_{t-1}^s + H_t^s$$，其中\\(H_t^s\\)是在t轮对于槽类型s的假设的集合。</p>\n<p>另外，也是本文中比较新的一点是<strong>马尔科夫判别模型</strong>，也就是将生成模型和判别模型相结合：</p>\n<p>生成模型： \\(P(S_t) = k \\sum_{S_{t-1} \\in S} P(O^t | S_t) P(S_t | S_{t-1}) P(S_t) \\)</p>\n<p>判别模型： \\(P(S_t | O_1^t) = f(O_1^t)\\)</p>\n<p>马尔科夫判别模型：\\((P(S_t | O_1^t) = \\sum_{S_{t-1} \\in S} P(S_t | O_1^t, S_{t-1}) P( S_{t-1} | O_1^{t-1})\\)</p>\n<p>在训练过程中，由于当前叙述之前所有的标签都是已知的，而预测过程中之前的都是预测的结果，这会导致训练的模型会过度依赖状态转移矩阵，这个问题称作<strong>标签过耦合</strong>问题。为了解决这个问题，他们设计了一个2步训练法：</p>\n<ul>\n<li><p>第一步：训练一个传统的判别模型。</p>\n</li>\n<li><p>第二部：在第一步的基础上训练状态转移特征。</p>\n</li>\n</ul>\n<p>这样第一步预测的错误会在一定程度上解耦相邻的状态直接的联系。最终这个模型在准确度和L2距离的结果分别为0.576，0.652。 </p>\n<h5 id=\"循环神经网络-9\"><a href=\"#循环神经网络-9\" class=\"headerlink\" title=\"循环神经网络 [9]\"></a>循环神经网络 [9]</h5><!-- team 3 -->\n<p>这个模型的注重点在于模型对扩展域的自适应性的问题（即训练数据中不存在的槽类型即槽值）。其中，系统将用户叙述中的槽类型和槽值分别用&lt;slot>和&lt;value>来替代。由于对于每个叙述表示的都是在不同的槽类型和槽值之间的概率分布，因此若一个新的叙述的概率分布与系统的已知的叙述中的概率分布类似，则可以认为两者具有类似的的槽类型和槽值的关系。</p>\n<div align=\"center\"><br>    <img src=\"/images/intent_dstc_rnn.png\" width=\"400\" align=\"center/\"><br></div>\n\n<p>通过上图的过程，我们可以得出 “Jamaican food”标记为 “s=food and v=jamaican”，若新的叙述为 “The Girton area” 其替换为&lt;slot>和&lt;value>的概率分布与前者类似，因此可以得出 “s=area and v=girton”。最终这个模型在准确度和L2距离的结果分别为0.646，0.534。</p>\n<h5 id=\"基于规则的模型-10\"><a href=\"#基于规则的模型-10\" class=\"headerlink\" title=\"基于规则的模型 [10]\"></a>基于规则的模型 [10]</h5><!-- team 5 -->\n<p>这篇文章设定了很多推理规则，并将规则看做是满足某些线性约束的特殊类型的多项式函数，<strong>马尔可夫贝叶斯多项式 (Markov Bayesian Polynomial, MBP)</strong>。在某些假设下，这个模型的求解过程可被视为整数线性规划问题 (Integer Linear Programming, ILP)，实验证明其具有很好的泛化能力。最终这个模型在准确度和L2距离的结果分别为0.610，0.556。 </p>\n<h5 id=\"知识驱动的基于规则的模型-11\"><a href=\"#知识驱动的基于规则的模型-11\" class=\"headerlink\" title=\"知识驱动的基于规则的模型 [11]\"></a>知识驱动的基于规则的模型 [11]</h5><!-- team 4 -->\n<p>这篇文章认为目前的语言理解模型无法识别用户不关注的点，以及一些易产生歧义的信息，因此他们提出了一种基于知识的方法。对于每轮叙述，会基于机器的上一个动作act，用户的acts以及之前的act的概率分布猜想生成新的用户目标的概率分布猜想，类似于一个演绎推理的过程。最终这个模型在准确度和L2距离的结果分别为0.630，0.627。</p>\n<p>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</p>\n<p>[1] Overview of the NLPCC 2018 Shared Task: Spoken Language Understanding in Task-Oriented Dialog Systems<br>[2] Learning Dialogue History for Spoken Language Understanding.<br>[3] The Sogou Spoken Language Understanding System for the NLPCC 2018 Evaluation.<br>[4] Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems.<br>[5] A Frame Tracking Model for Memory-Enhanced Dialogue Systems.<br>[6] The Dialog State Tracking Challenge Series: A Review, Learning End-To-End Goal-oriented Dialog.<br>[7] Adobe-MIT submission to the DSTC 4 Spoken Language Understanding pilot task.<br>[8] Markovian discriminative modeling for cross-domain dialog state tracking.<br>[9] Robust Dialog State Tracking Using Delexicalised Recurrent Neural Networks and Unsupervised Adaptation.<br>[10] A generalized rule based tracker for dialogue state tracking.<br>[11] Knowledge-based dialog state tracking.</p>\n","site":{"data":{}},"excerpt":"<p>自然语言理解（Natural Language Understanding, NLU）是NLP领域的一个分支，在自然语言理解的过程中，首先就是对意图（Intent）分类，然后接着对槽位（Slot）填充。</p>","more":"<p>意图分类时一个典型的文本分类的问题，常用的方法如下：</p>\n<ul>\n<li>基于规则的方法<br>用户人工定义一些匹配规则进行分类。</li>\n<li>机器学习的方法<br>SVM, Decision Tree等等。</li>\n<li>深度学习的方法<br>目前更加推崇使用 End-to-End 的网络进行分类。</li>\n</ul>\n<p>最近收集了一些关于意图分类以及槽填充的相关的数据集以及对应的测试指标。</p>\n<h2 id=\"中文数据集\"><a href=\"#中文数据集\" class=\"headerlink\" title=\"中文数据集\"></a>中文数据集</h2><h3 id=\"NLPCC-2018-Task4-Spoken-Language-Understanding-in-Task-Oriented-Dialogue-Systems\"><a href=\"#NLPCC-2018-Task4-Spoken-Language-Understanding-in-Task-Oriented-Dialogue-Systems\" class=\"headerlink\" title=\"NLPCC 2018 Task4 - Spoken Language Understanding in Task-Oriented Dialogue Systems\"></a><a href=\"http://tcci.ccf.org.cn/conference/2018/taskdata.php\" target=\"_blank\" rel=\"noopener\">NLPCC 2018 Task4</a> - Spoken Language Understanding in Task-Oriented Dialogue Systems</h3><h4 id=\"数据描述-1\"><a href=\"#数据描述-1\" class=\"headerlink\" title=\"数据描述 [1]\"></a>数据描述 [1]</h4><p>这个数据集来源于某车载产品的真实日志数据，主要涉及音乐，导航以及打电话等等领域，11种意图以及15种槽值类型。其中包括 <strong>5.8K</strong> 次会话，总共有 <strong>26K</strong> 次叙述（Utterance）。特别地，这个数据集仅仅包含了用户的输入（没有系统的回复），并且针对错误的槽值进行了修正，如将“什话”修正为“神话”。</p>\n<ul>\n<li>训练集：4705次会话, 21352次叙述。</li>\n<li>验证集：1177次会话, 5350次叙述。 （训练集：验证集 约 4:1）</li>\n</ul>\n<p>数据格式<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">session ID    用户query              意图                       语义槽标注</span><br><span class=\"line\">    1           打电话\t   phone_call.make_a_phone_call\t        打电话</span><br><span class=\"line\">    1\t      我想听美观\t        music.play\t          我想听&lt;song&gt;美观&lt;/song&gt;</span><br><span class=\"line\">    1\t      我想听什话\t        music.play\t          我想听&lt;song&gt;什话||神话&lt;/song&gt;</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"评估方法\"><a href=\"#评估方法\" class=\"headerlink\" title=\"评估方法\"></a>评估方法</h4><p>这个比赛主要有两个评估方法:</p>\n<ul>\n<li><p>意图分类，评估方法为F1值，具体的计算方法如下：</p>\n<div align=\"center\"><br>  <img src=\"/images/intent_f1.png\" width=\"500\"><br></div>\n</li>\n<li><p>意图分类以及槽填充，评估方法是准确度。即意图分类以及所有的槽位都完全正确。</p>\n</li>\n</ul>\n<h4 id=\"主要算法\"><a href=\"#主要算法\" class=\"headerlink\" title=\"主要算法\"></a>主要算法</h4><p>总共有16个队伍参加了这个比赛，但是只有两个队伍开源了他们的方法，分别是HLSTM-SLU模型和Sogou团队的模型。具体结果如下：</p>\n<div align=\"center\"><br>    <img src=\"/images/intent_results.png\" width=\"500\" align=\"center/\"><br></div>\n\n<h5 id=\"HLSTM-SLU-2\"><a href=\"#HLSTM-SLU-2\" class=\"headerlink\" title=\"HLSTM-SLU [2]\"></a>HLSTM-SLU [2]</h5><p>这个可以看做是深度学习的方法和传统的机器学习方法相结合。模型结构如下：</p>\n<div align=\"center\"><br>    <img src=\"/images/intent_hlstm.png\" width=\"500\" align=\"center/\"><br></div>\n\n<p>这个模型主要由三个LSTM组成，两个双向LSTM处理输入和输出，一个单向LSTM处理一个会话中的多个叙述。</p>\n<ul>\n<li>输入Bi-LSTM<br>输入：Character Embedding + POS + Domain<br>其中POS表示对每个字进行词性标注，并用类似于BI的方法进行编码；Domain表示不同领域的词，也用BI的方法进行编码，具体实例如下：</li>\n</ul>\n<div align=\"center\"><br>    <img src=\"/images/intent_input.png\" width=\"500\" align=\"center/\"><br></div>\n\n<ul>\n<li><p>Session LSTM<br>输入：一次对话中的每轮的描述经过输入Bi-LSTM的输出经过最大池化之后的结果。<br>输出：<strong>意图的类别</strong></p>\n</li>\n<li><p>输出Bi-LSTM<br>输入：Session LSTM + 输入Bi-LSTM<br>输出：<strong>槽位标注</strong></p>\n</li>\n</ul>\n<p>注：并没有直接使用LSTM的结果作为最终的结果，而是根据 <strong>CRF</strong> 预测最优的序列。</p>\n<p><strong>Trick</strong>: 使用 <strong>over sampling</strong> 解决意图类别中的样本不均衡的问题，并在过程中使用规则识别了一部分小样本的意图。</p>\n<p><strong>结果</strong>：这个模型在两个评估方法的结果最终为94.19%，90.84%。</p>\n<h5 id=\"Sogou-3\"><a href=\"#Sogou-3\" class=\"headerlink\" title=\"Sogou [3]\"></a>Sogou [3]</h5><p>这个模型没有使用深度学习的方法，而是使用传统的机器学习中的序列标注方法。首先，他们认为用户的query可以根据是否有显性的意图词分为两类（这一部分主要根据实体词匹配算法得到）。对于有显性意图词语的query，采用<strong>基于规则</strong>的处理的方法进行标注；剩下的部分采用<strong>基于模型</strong>的方法，具体的模型方法分为5步：</p>\n<ol>\n<li><p>对query进行分词和词性标注（POS）。</p>\n</li>\n<li><p>寻找槽边界：先对处理后的query使用character embedding + word embedding; 根据BILOU原则，使用CRF对其进行序列标注。</p>\n</li>\n<li><p>槽分类：根据槽边界检测结果的character embedding + word embedding以及词性标注结果POS，通过逻辑回归的方式（Logistic Regression）进行分类。</p>\n</li>\n<li><p>槽修正：若槽类别预测错误，则根据词之间的相似性寻找真实槽类别中的所有的值与之进行相似度比较，进而修正结果。</p>\n</li>\n<li><p>意图分类：使用<strong>XGBoost</strong>的方法，根据word embedding，query长度，槽类别进行意图分类。</p>\n</li>\n</ol>\n<p>注：由于训练样本比较少，针对模型预测错误的数据，他们根据比较query与Sogou语音中最匹配的进行替换，最终针对意图分类增加了500个数据，槽填充增加了1000个数据。</p>\n<p><strong>结果</strong>：这个模型在两个评估方法的结果最终为96.11%，94.49%。</p>\n<h2 id=\"英文数据集\"><a href=\"#英文数据集\" class=\"headerlink\" title=\"英文数据集\"></a>英文数据集</h2><h3 id=\"Frame\"><a href=\"#Frame\" class=\"headerlink\" title=\"Frame\"></a><a href=\"https://datasets.maluuba.com/Frames/dl\" target=\"_blank\" rel=\"noopener\">Frame</a></h3><h4 id=\"数据描述-4\"><a href=\"#数据描述-4\" class=\"headerlink\" title=\"数据描述 [4]\"></a>数据描述 [4]</h4><p>这个数据集主要针对航班和酒店预订，来源于基于Wizard-of-Oz(WOz)设定的人机对话的过程（实际上是一个人假扮机器）。其中包括 <strong>1369</strong> 个对话, 总共有 <strong>19986</strong> 轮。</p>\n<p><strong>数据格式</strong><br>每一次叙述都包含 ‘author’, ‘text’, ‘labels’, ‘timestamp’, ‘frames’(‘frame id’, ‘frame parent id’, ‘requests, binary questions, compare requests’, ‘info’), ‘db’字段。其中 ‘labels’记录当前的active_frame以及对话过程中的Act(包括act名称以及对应的slot类型和值)， ‘info’字段主要为了标注对于槽位值是否为否定的。</p>\n<p><strong>Act类型</strong>：inform, offer, request, switch frame, suggest, no result, thankyou, goodbye…..</p>\n<h4 id=\"评估方法-1\"><a href=\"#评估方法-1\" class=\"headerlink\" title=\"评估方法\"></a>评估方法</h4><p>微软在提出这个数据集的同时，也定义了一个任务Frame Tracking，这个任务与State Tracking不同的是，它可以同时追踪一个frame与之前几轮相关的frame，以及由一个frame转变到多个frame，例如用户要求系统可以推荐4个符合条件的旅行，如下图所示：</p>\n<div align=\"center\"><br>    <img src=\"/images/intent_frame.png\" width=\"300\" align=\"center/\"><br></div>\n\n<p>这个任务就是需要预测是否有新的frame生成。如果有，则预测其目的Act，限制条件Ref Labels以及之前相关的Frame ID，如果预测结果完全匹配，则认为预测正确，最后计算准确度。同时计算总的预测有新的frame生成的叙述个数，计算其识别新frame生成的准确度。</p>\n<h4 id=\"主要算法-1\"><a href=\"#主要算法-1\" class=\"headerlink\" title=\"主要算法\"></a>主要算法</h4><h5 id=\"Baseline-4\"><a href=\"#Baseline-4\" class=\"headerlink\" title=\"Baseline [4]\"></a>Baseline [4]</h5><p>由下图可知模型结构，针对叙述中的每个词，将其表示为trigrams的形式，然后通过一个embedding层，tanh激活层。针对Act分类和Slot分类，分别用一个双向的GRU实现，输入为每个词在激活层的输出。最后经由一个softmax分类层得到最终的类别。</p>\n<div align=\"center\"><br>    <img src=\"/images/intent_frame_baseline.png\" width=\"300\" align=\"center/\"><br></div>\n\n<p><strong>结果</strong>：这个模型在两个评估方法的结果最终为：frame识别准确度0.24 ± 0.02, frame新建识别准确度为0.49 ± 0.03。</p>\n<h5 id=\"Frame-Tracking-Model-for-Memory-Enhanced-Dialogue-Systems-5\"><a href=\"#Frame-Tracking-Model-for-Memory-Enhanced-Dialogue-Systems-5\" class=\"headerlink\" title=\"Frame Tracking Model for Memory-Enhanced Dialogue Systems [5]\"></a>Frame Tracking Model for Memory-Enhanced Dialogue Systems [5]</h5><p>微软的团队随后提出了一个新的模型来处理这个问题。</p>\n<h6 id=\"输入预处理\"><a href=\"#输入预处理\" class=\"headerlink\" title=\"输入预处理\"></a>输入预处理</h6><ul>\n<li><p>Token Encoding：每个词用trigrams的形式表示。如：“hello” -&gt; #he, hel, ell, llo, lo#。构建trigrams词典D-T，每个词都表示为（Trigrams ID）。 </p>\n</li>\n<li><p>用户叙述：将叙述中的每个词用trigrams的形式表示，这些trigrams经过一个embedding层，输出的向量的和来表示这个token，再经过一个 Bidirectional GRU，将所有的隐层状态堆叠起来来表示此轮的叙述。</p>\n</li>\n<li><p>Frame：每个frame由槽类型Slot和槽值Value组成，与trigrams类似，分别构建槽类型词典D-S和槽值词典D-V。即，每个frame表示为（Slot ID, Token ID）。</p>\n</li>\n<li><p>Act：每个act由行动类型Act，槽类型Slot和槽值Value组成。即，每个act表示为（Act ID, Slot ID, Token ID）。</p>\n</li>\n</ul>\n<h6 id=\"模型输入\"><a href=\"#模型输入\" class=\"headerlink\" title=\"模型输入\"></a>模型输入</h6><ul>\n<li><p>当前轮之前所有的frames （Slot ID, Trigrams ID）</p>\n</li>\n<li><p>叙述 （Trigrams ID）</p>\n</li>\n<li><p>当前轮对应的行动Act （Act ID, Slot ID, Trigrams ID）</p>\n</li>\n</ul>\n<h6 id=\"模型结构\"><a href=\"#模型结构\" class=\"headerlink\" title=\"模型结构\"></a>模型结构</h6><div align=\"center\"><br>    <img src=\"/images/intent_frame_model.png\" width=\"400\" align=\"center/\"><br></div>\n\n<ol>\n<li><p>对于frames，（Slot, Token）经过一个GRU，将隐层其映射为一个256维的向量，所有的隐层堆叠起来表示最终的frames，\\(m_f\\) （|F| * 256）；对于act，将（Act, Slot, Token）输入一个 Bidirectional GRU，将隐层以及叙述embedding连接起来，并将其映射为 \\(m_{asv}\\) （N * 256, N为act的数量）来表示acts；</p>\n</li>\n<li><p>通过计算 \\(m_f\\) 和 \\(m_{asv}\\) 的点乘的结果 \\(S_m\\) （N * |F|）来表示act和frame之间的相似性，也可以看做基于frame的一个多项分布。特别地，他们还事先根据act中的槽值与frame之间的槽值的相似性计算了act与frame之间的相似性 \\(S_L\\) 。最终，根据两者的线性组合来表示act与frame之间的相似性 S。</p>\n</li>\n<li><p>在用户新输入一个（act, slot, value）表示时，根据这个相似矩阵可以得到一个多项分布\\(p_{asv, f}\\) ，从而得到与之相关的frames，从而也就得到了他们实验的衡量指标之一，基于槽分类slot的frame追踪。</p>\n</li>\n<li><p>另外，对于每一个（act，frame）对，他们会根据输入的act, 以及用户的叙述经过两个全连接层得到最终的 \\(p_{a, f}\\) ，从而也就得到了他们实验的另一个衡量指标，基于行动act的frame追踪。</p>\n</li>\n</ol>\n<p><strong>注</strong>：这里没有详细介绍实验的一些完善trick，如模型图中的\\(g_c\\)， \\(g_n\\)， \\(h_d\\)， \\(h_c\\)，详情请看论文。</p>\n<p><strong>结果</strong>：这个模型在基于槽分类的准确度为76.43 ± 4.49，基于行动Act分类的准确度为95.66 ± 2.34。</p>\n<h3 id=\"DSTC-Dialog-State-Tracking-Challenge-6-7\"><a href=\"#DSTC-Dialog-State-Tracking-Challenge-6-7\" class=\"headerlink\" title=\"DSTC (Dialog State Tracking Challenge) [6, 7]\"></a><a href=\"https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/\" target=\"_blank\" rel=\"noopener\">DSTC</a> (Dialog State Tracking Challenge) [6, 7]</h3><h4 id=\"数据描述\"><a href=\"#数据描述\" class=\"headerlink\" title=\"数据描述\"></a>数据描述</h4><p>DSTC 是针对一系列的对话数据，完成对话跟踪的任务。也就是针对每一个数据集，意在可以根据之前的状态来预测新的对话的状态。目前DSTC数据已经更新到DSCT6，下面将简单介绍各个版本的数据。</p>\n<ul>\n<li><p>DSTC 1<br>这个数据集包括城市BUS的预定电话中的对话数据。<strong>12963</strong>轮训练数据，<strong>2485</strong>轮测试数据。</p>\n</li>\n<li><p>DSTC 2&amp;3<br>在DSTC 1的基础上，增加了关于餐厅，旅游信息等等相关的对话。其中DSTC2包括<strong>2218</strong>轮训练数据，<strong>1117</strong>轮测试数据；DSTC3包括<strong>3235</strong>轮训练数据，<strong>2275</strong>轮测试数据。数据中的<code>semantics</code>字段会对对话中的槽slot和目的act标注。下面是一个数据样例：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DSTC2 and DSTC3 (Training Set)</span><br><span class=\"line\">SYS: Which part of town?</span><br><span class=\"line\">USR: The north uh area</span><br><span class=\"line\">SYS: Which part of town?</span><br><span class=\"line\">USR: A cheap place <span class=\"keyword\">in</span> the north</span><br><span class=\"line\">SYS: Clown cafe is a cheap restaurant <span class=\"keyword\">in</span> the north part of town. USR: Do you have any others like that?</span><br><span class=\"line\">SYS: Galleria is another cheap restaurant <span class=\"keyword\">in</span> the north. USR: What is their phone number and address?</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>DSTC 4<br>这个数据集是人与人之间关于旅游信息的对话数据，其中有一个子任务Spoken language understanding，意在给每个叙述中的目的acts和语义槽slots打标签。挑战赛总共收到了5个提交模型[7]，其中最好的结果的F1值约为0.52。其中三个模型分别为：</p>\n<ul>\n<li>SVM分类模型<br>输入：叙述的unigrams, bigrams, trigrams，标签（标注当前叙述与上一个叙述是否为同一个人）</li>\n<li>逻辑回归模型<br>输入：同上。</li>\n<li>随机森林模型<br>输入：问题数目，标签（标注当前叙述与上一个叙述是否为同一个人），标签（标注当前叙述与上上一个叙述是否为同一个人），标签（标注这个人是导游还是旅客）</li>\n</ul>\n</li>\n<li><p>DSTC 5<br>这个数据集针对跨语言测量，也就是训练集为英语数据，测试集为中文数据。</p>\n</li>\n<li><p>DSTC 6<br>这个数据集关注在多轮对话，其任务包括端到端的目标导向的对话学习，端到端会话建模，以及对话故障检测。</p>\n</li>\n</ul>\n<h4 id=\"评估方法-（DSTC2-amp-3）\"><a href=\"#评估方法-（DSTC2-amp-3）\" class=\"headerlink\" title=\"评估方法 （DSTC2 &amp; 3）\"></a>评估方法 （DSTC2 &amp; 3）</h4><ul>\n<li>准确度：正确预测的轮数占数据总轮数的百分数。</li>\n<li>L2距离：向量1为正确预测的轮标为1，其余为0组成的向量；向量2为根据模型得到的每一个的概率值组成的向量，计算向量之间的距离。</li>\n</ul>\n<h4 id=\"主要算法-2\"><a href=\"#主要算法-2\" class=\"headerlink\" title=\"主要算法\"></a>主要算法</h4><p>这里我们主要关注在DSTC3上的四个模型。</p>\n<h5 id=\"马尔科夫判别模型-8\"><a href=\"#马尔科夫判别模型-8\" class=\"headerlink\" title=\"马尔科夫判别模型 [8]\"></a>马尔科夫判别模型 [8]</h5><!-- team7 -->\n<p>这是来自中科院声学与语言理解研究所的一个模型。为了能够支持未知的领域，因此这篇文章将通过假设每一轮的可能的域来动态的更新分类的类别。<br>$$ Y_t^s = Y_{t-1}^s + H_t^s$$，其中\\(H_t^s\\)是在t轮对于槽类型s的假设的集合。</p>\n<p>另外，也是本文中比较新的一点是<strong>马尔科夫判别模型</strong>，也就是将生成模型和判别模型相结合：</p>\n<p>生成模型： \\(P(S_t) = k \\sum_{S_{t-1} \\in S} P(O^t | S_t) P(S_t | S_{t-1}) P(S_t) \\)</p>\n<p>判别模型： \\(P(S_t | O_1^t) = f(O_1^t)\\)</p>\n<p>马尔科夫判别模型：\\((P(S_t | O_1^t) = \\sum_{S_{t-1} \\in S} P(S_t | O_1^t, S_{t-1}) P( S_{t-1} | O_1^{t-1})\\)</p>\n<p>在训练过程中，由于当前叙述之前所有的标签都是已知的，而预测过程中之前的都是预测的结果，这会导致训练的模型会过度依赖状态转移矩阵，这个问题称作<strong>标签过耦合</strong>问题。为了解决这个问题，他们设计了一个2步训练法：</p>\n<ul>\n<li><p>第一步：训练一个传统的判别模型。</p>\n</li>\n<li><p>第二部：在第一步的基础上训练状态转移特征。</p>\n</li>\n</ul>\n<p>这样第一步预测的错误会在一定程度上解耦相邻的状态直接的联系。最终这个模型在准确度和L2距离的结果分别为0.576，0.652。 </p>\n<h5 id=\"循环神经网络-9\"><a href=\"#循环神经网络-9\" class=\"headerlink\" title=\"循环神经网络 [9]\"></a>循环神经网络 [9]</h5><!-- team 3 -->\n<p>这个模型的注重点在于模型对扩展域的自适应性的问题（即训练数据中不存在的槽类型即槽值）。其中，系统将用户叙述中的槽类型和槽值分别用&lt;slot>和&lt;value>来替代。由于对于每个叙述表示的都是在不同的槽类型和槽值之间的概率分布，因此若一个新的叙述的概率分布与系统的已知的叙述中的概率分布类似，则可以认为两者具有类似的的槽类型和槽值的关系。</p>\n<div align=\"center\"><br>    <img src=\"/images/intent_dstc_rnn.png\" width=\"400\" align=\"center/\"><br></div>\n\n<p>通过上图的过程，我们可以得出 “Jamaican food”标记为 “s=food and v=jamaican”，若新的叙述为 “The Girton area” 其替换为&lt;slot>和&lt;value>的概率分布与前者类似，因此可以得出 “s=area and v=girton”。最终这个模型在准确度和L2距离的结果分别为0.646，0.534。</p>\n<h5 id=\"基于规则的模型-10\"><a href=\"#基于规则的模型-10\" class=\"headerlink\" title=\"基于规则的模型 [10]\"></a>基于规则的模型 [10]</h5><!-- team 5 -->\n<p>这篇文章设定了很多推理规则，并将规则看做是满足某些线性约束的特殊类型的多项式函数，<strong>马尔可夫贝叶斯多项式 (Markov Bayesian Polynomial, MBP)</strong>。在某些假设下，这个模型的求解过程可被视为整数线性规划问题 (Integer Linear Programming, ILP)，实验证明其具有很好的泛化能力。最终这个模型在准确度和L2距离的结果分别为0.610，0.556。 </p>\n<h5 id=\"知识驱动的基于规则的模型-11\"><a href=\"#知识驱动的基于规则的模型-11\" class=\"headerlink\" title=\"知识驱动的基于规则的模型 [11]\"></a>知识驱动的基于规则的模型 [11]</h5><!-- team 4 -->\n<p>这篇文章认为目前的语言理解模型无法识别用户不关注的点，以及一些易产生歧义的信息，因此他们提出了一种基于知识的方法。对于每轮叙述，会基于机器的上一个动作act，用户的acts以及之前的act的概率分布猜想生成新的用户目标的概率分布猜想，类似于一个演绎推理的过程。最终这个模型在准确度和L2距离的结果分别为0.630，0.627。</p>\n<p>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</p>\n<p>[1] Overview of the NLPCC 2018 Shared Task: Spoken Language Understanding in Task-Oriented Dialog Systems<br>[2] Learning Dialogue History for Spoken Language Understanding.<br>[3] The Sogou Spoken Language Understanding System for the NLPCC 2018 Evaluation.<br>[4] Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems.<br>[5] A Frame Tracking Model for Memory-Enhanced Dialogue Systems.<br>[6] The Dialog State Tracking Challenge Series: A Review, Learning End-To-End Goal-oriented Dialog.<br>[7] Adobe-MIT submission to the DSTC 4 Spoken Language Understanding pilot task.<br>[8] Markovian discriminative modeling for cross-domain dialog state tracking.<br>[9] Robust Dialog State Tracking Using Delexicalised Recurrent Neural Networks and Unsupervised Adaptation.<br>[10] A generalized rule based tracker for dialogue state tracking.<br>[11] Knowledge-based dialog state tracking.</p>"},{"title":"First Step to Establish the Blog","_content":"\n让我们搭一个美美的博客，一起写写写吧~~~\n\n<!-- more --> \n\n## Requirement\n\n​\tbrew, hexo, Node.js\n\n### Hexo项目\n\n``` bash\n$ hexo init           # 新建博客目录\n$ hexo new \"postname\" # 生成postname.md文件\n$ hexo clean          # 清空生成的网页\n$ hexo generate       # 根据当前目录下文件生成静态网页\n$ hexo server \t      # 启动服务器\n```\n\n通过访问localhost:4000可以在本地调试。文件目录`source`下的`_posts`中可以添加用户新增加的博客内容（Markdown语法）。\n\nMore info: [Heox](https://hexo.io/docs/)\n\n### 修改主题\n\n``` bash\n$ git clone https://github.com/theme-next/hexo-theme-next themes/next\n```\n\n修改`config.yml`配置文件中的theme属性，将其设置为next。另外常见的Next主题中常见的属性：\n``` bash\nauto_excerpt:   # 可通过 <!-- more --> 标签自动截断, 增加阅读全文按钮。\n  enable: true\n  length: 150\n\nbusuanzi_count: # 监听网页浏览量。\n  enable: true\n```\n\n### 添加新的导航栏\n\n``` bash\n$ hexo new page tags   # 添加tags标签页\n```\n\n修改`source`目录下的`tags`中的`index.md`如下：\n\n```\n---\ntitle: tags\ndate: 2018-10-30 17:23:49\ntype: \"tags\"\n---\n```\n\n在菜单中添加链接。编辑`config.yml`配置文件中的menu属性，如下：\n\n```\nmenu:\n  home: /\n  archives: /archives\n  tags : /tags\n```\n\n### 部署到 Github\n\n修改`config.yml`配置文件中的deploy属性：\n\n``` bash\ndeploy:\n  type: git \n  repo: https://github.com/test/test.github.io.git  # github路径\n```\n\n通过下面的指令实现部署：\n``` bash\n$ npm install hexo-deployer-git --save\n$ hexo deploy\n```\n\n### Google 收录博客网站\n\n1. 添加站点：用自己的 Google 帐号登陆 [Webmaster Central](https://www.google.com/webmasters/verification/home?hl=en)。\n\n2. 验证站点: 将网站上的验证文件放在 `source` 文件下，在站点配置文件配置如下：\n``` bash\nskip_render: google10bb50e0b38f396b.html\n```\n\n3. 产生 sitemap：借助  hexo-generator-sitemap 工具自动生成，并在`config.yml`里配置一下：\n``` bash\nnpm install hexo-generator-sitemap --save\n```\n\t``` bash\n\tsitemap:\n\t    path: sitemap.xml\n\t```\n\n4. 重新编译生成\n``` bash\nhexo generate\n```\n","source":"_posts/first_step.md","raw":"---\ntitle: First Step to Establish the Blog\ncategories: Note\ntags:\n  - Tools\n---\n\n让我们搭一个美美的博客，一起写写写吧~~~\n\n<!-- more --> \n\n## Requirement\n\n​\tbrew, hexo, Node.js\n\n### Hexo项目\n\n``` bash\n$ hexo init           # 新建博客目录\n$ hexo new \"postname\" # 生成postname.md文件\n$ hexo clean          # 清空生成的网页\n$ hexo generate       # 根据当前目录下文件生成静态网页\n$ hexo server \t      # 启动服务器\n```\n\n通过访问localhost:4000可以在本地调试。文件目录`source`下的`_posts`中可以添加用户新增加的博客内容（Markdown语法）。\n\nMore info: [Heox](https://hexo.io/docs/)\n\n### 修改主题\n\n``` bash\n$ git clone https://github.com/theme-next/hexo-theme-next themes/next\n```\n\n修改`config.yml`配置文件中的theme属性，将其设置为next。另外常见的Next主题中常见的属性：\n``` bash\nauto_excerpt:   # 可通过 <!-- more --> 标签自动截断, 增加阅读全文按钮。\n  enable: true\n  length: 150\n\nbusuanzi_count: # 监听网页浏览量。\n  enable: true\n```\n\n### 添加新的导航栏\n\n``` bash\n$ hexo new page tags   # 添加tags标签页\n```\n\n修改`source`目录下的`tags`中的`index.md`如下：\n\n```\n---\ntitle: tags\ndate: 2018-10-30 17:23:49\ntype: \"tags\"\n---\n```\n\n在菜单中添加链接。编辑`config.yml`配置文件中的menu属性，如下：\n\n```\nmenu:\n  home: /\n  archives: /archives\n  tags : /tags\n```\n\n### 部署到 Github\n\n修改`config.yml`配置文件中的deploy属性：\n\n``` bash\ndeploy:\n  type: git \n  repo: https://github.com/test/test.github.io.git  # github路径\n```\n\n通过下面的指令实现部署：\n``` bash\n$ npm install hexo-deployer-git --save\n$ hexo deploy\n```\n\n### Google 收录博客网站\n\n1. 添加站点：用自己的 Google 帐号登陆 [Webmaster Central](https://www.google.com/webmasters/verification/home?hl=en)。\n\n2. 验证站点: 将网站上的验证文件放在 `source` 文件下，在站点配置文件配置如下：\n``` bash\nskip_render: google10bb50e0b38f396b.html\n```\n\n3. 产生 sitemap：借助  hexo-generator-sitemap 工具自动生成，并在`config.yml`里配置一下：\n``` bash\nnpm install hexo-generator-sitemap --save\n```\n\t``` bash\n\tsitemap:\n\t    path: sitemap.xml\n\t```\n\n4. 重新编译生成\n``` bash\nhexo generate\n```\n","slug":"first_step","published":1,"date":"2018-10-30T10:18:42.174Z","updated":"2018-11-04T09:11:11.814Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo46iqiq00041wzmspy9o4rp","content":"<p>让我们搭一个美美的博客，一起写写写吧~~~</p>\n<a id=\"more\"></a> \n<h2 id=\"Requirement\"><a href=\"#Requirement\" class=\"headerlink\" title=\"Requirement\"></a>Requirement</h2><p>​    brew, hexo, Node.js</p>\n<h3 id=\"Hexo项目\"><a href=\"#Hexo项目\" class=\"headerlink\" title=\"Hexo项目\"></a>Hexo项目</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo init           <span class=\"comment\"># 新建博客目录</span></span><br><span class=\"line\">$ hexo new <span class=\"string\">\"postname\"</span> <span class=\"comment\"># 生成postname.md文件</span></span><br><span class=\"line\">$ hexo clean          <span class=\"comment\"># 清空生成的网页</span></span><br><span class=\"line\">$ hexo generate       <span class=\"comment\"># 根据当前目录下文件生成静态网页</span></span><br><span class=\"line\">$ hexo server \t      <span class=\"comment\"># 启动服务器</span></span><br></pre></td></tr></table></figure>\n<p>通过访问localhost:4000可以在本地调试。文件目录<code>source</code>下的<code>_posts</code>中可以添加用户新增加的博客内容（Markdown语法）。</p>\n<p>More info: <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">Heox</a></p>\n<h3 id=\"修改主题\"><a href=\"#修改主题\" class=\"headerlink\" title=\"修改主题\"></a>修改主题</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git <span class=\"built_in\">clone</span> https://github.com/theme-next/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>\n<p>修改<code>config.yml</code>配置文件中的theme属性，将其设置为next。另外常见的Next主题中常见的属性：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto_excerpt:   <span class=\"comment\"># 可通过 &lt;!-- more --&gt; 标签自动截断, 增加阅读全文按钮。</span></span><br><span class=\"line\">  <span class=\"built_in\">enable</span>: <span class=\"literal\">true</span></span><br><span class=\"line\">  length: 150</span><br><span class=\"line\"></span><br><span class=\"line\">busuanzi_count: <span class=\"comment\"># 监听网页浏览量。</span></span><br><span class=\"line\">  <span class=\"built_in\">enable</span>: <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"添加新的导航栏\"><a href=\"#添加新的导航栏\" class=\"headerlink\" title=\"添加新的导航栏\"></a>添加新的导航栏</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new page tags   <span class=\"comment\"># 添加tags标签页</span></span><br></pre></td></tr></table></figure>\n<p>修改<code>source</code>目录下的<code>tags</code>中的<code>index.md</code>如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---</span><br><span class=\"line\">title: tags</span><br><span class=\"line\">date: 2018-10-30 17:23:49</span><br><span class=\"line\">type: &quot;tags&quot;</span><br><span class=\"line\">---</span><br></pre></td></tr></table></figure>\n<p>在菜单中添加链接。编辑<code>config.yml</code>配置文件中的menu属性，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">menu:</span><br><span class=\"line\">  home: /</span><br><span class=\"line\">  archives: /archives</span><br><span class=\"line\">  tags : /tags</span><br></pre></td></tr></table></figure>\n<h3 id=\"部署到-Github\"><a href=\"#部署到-Github\" class=\"headerlink\" title=\"部署到 Github\"></a>部署到 Github</h3><p>修改<code>config.yml</code>配置文件中的deploy属性：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  <span class=\"built_in\">type</span>: git </span><br><span class=\"line\">  repo: https://github.com/<span class=\"built_in\">test</span>/test.github.io.git  <span class=\"comment\"># github路径</span></span><br></pre></td></tr></table></figure>\n<p>通过下面的指令实现部署：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-deployer-git --save</span><br><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Google-收录博客网站\"><a href=\"#Google-收录博客网站\" class=\"headerlink\" title=\"Google 收录博客网站\"></a>Google 收录博客网站</h3><ol>\n<li><p>添加站点：用自己的 Google 帐号登陆 <a href=\"https://www.google.com/webmasters/verification/home?hl=en\" target=\"_blank\" rel=\"noopener\">Webmaster Central</a>。</p>\n</li>\n<li><p>验证站点: 将网站上的验证文件放在 <code>source</code> 文件下，在站点配置文件配置如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">skip_render: google10bb50e0b38f396b.html</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>产生 sitemap：借助  hexo-generator-sitemap 工具自动生成，并在<code>config.yml</code>里配置一下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-generator-sitemap --save</span><br></pre></td></tr></table></figure>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sitemap:</span><br><span class=\"line\">    path: sitemap.xml</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>重新编译生成</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo generate</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>让我们搭一个美美的博客，一起写写写吧~~~</p>","more":"<h2 id=\"Requirement\"><a href=\"#Requirement\" class=\"headerlink\" title=\"Requirement\"></a>Requirement</h2><p>​    brew, hexo, Node.js</p>\n<h3 id=\"Hexo项目\"><a href=\"#Hexo项目\" class=\"headerlink\" title=\"Hexo项目\"></a>Hexo项目</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo init           <span class=\"comment\"># 新建博客目录</span></span><br><span class=\"line\">$ hexo new <span class=\"string\">\"postname\"</span> <span class=\"comment\"># 生成postname.md文件</span></span><br><span class=\"line\">$ hexo clean          <span class=\"comment\"># 清空生成的网页</span></span><br><span class=\"line\">$ hexo generate       <span class=\"comment\"># 根据当前目录下文件生成静态网页</span></span><br><span class=\"line\">$ hexo server \t      <span class=\"comment\"># 启动服务器</span></span><br></pre></td></tr></table></figure>\n<p>通过访问localhost:4000可以在本地调试。文件目录<code>source</code>下的<code>_posts</code>中可以添加用户新增加的博客内容（Markdown语法）。</p>\n<p>More info: <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">Heox</a></p>\n<h3 id=\"修改主题\"><a href=\"#修改主题\" class=\"headerlink\" title=\"修改主题\"></a>修改主题</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git <span class=\"built_in\">clone</span> https://github.com/theme-next/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>\n<p>修改<code>config.yml</code>配置文件中的theme属性，将其设置为next。另外常见的Next主题中常见的属性：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto_excerpt:   <span class=\"comment\"># 可通过 &lt;!-- more --&gt; 标签自动截断, 增加阅读全文按钮。</span></span><br><span class=\"line\">  <span class=\"built_in\">enable</span>: <span class=\"literal\">true</span></span><br><span class=\"line\">  length: 150</span><br><span class=\"line\"></span><br><span class=\"line\">busuanzi_count: <span class=\"comment\"># 监听网页浏览量。</span></span><br><span class=\"line\">  <span class=\"built_in\">enable</span>: <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"添加新的导航栏\"><a href=\"#添加新的导航栏\" class=\"headerlink\" title=\"添加新的导航栏\"></a>添加新的导航栏</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new page tags   <span class=\"comment\"># 添加tags标签页</span></span><br></pre></td></tr></table></figure>\n<p>修改<code>source</code>目录下的<code>tags</code>中的<code>index.md</code>如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---</span><br><span class=\"line\">title: tags</span><br><span class=\"line\">date: 2018-10-30 17:23:49</span><br><span class=\"line\">type: &quot;tags&quot;</span><br><span class=\"line\">---</span><br></pre></td></tr></table></figure>\n<p>在菜单中添加链接。编辑<code>config.yml</code>配置文件中的menu属性，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">menu:</span><br><span class=\"line\">  home: /</span><br><span class=\"line\">  archives: /archives</span><br><span class=\"line\">  tags : /tags</span><br></pre></td></tr></table></figure>\n<h3 id=\"部署到-Github\"><a href=\"#部署到-Github\" class=\"headerlink\" title=\"部署到 Github\"></a>部署到 Github</h3><p>修改<code>config.yml</code>配置文件中的deploy属性：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  <span class=\"built_in\">type</span>: git </span><br><span class=\"line\">  repo: https://github.com/<span class=\"built_in\">test</span>/test.github.io.git  <span class=\"comment\"># github路径</span></span><br></pre></td></tr></table></figure>\n<p>通过下面的指令实现部署：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-deployer-git --save</span><br><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Google-收录博客网站\"><a href=\"#Google-收录博客网站\" class=\"headerlink\" title=\"Google 收录博客网站\"></a>Google 收录博客网站</h3><ol>\n<li><p>添加站点：用自己的 Google 帐号登陆 <a href=\"https://www.google.com/webmasters/verification/home?hl=en\" target=\"_blank\" rel=\"noopener\">Webmaster Central</a>。</p>\n</li>\n<li><p>验证站点: 将网站上的验证文件放在 <code>source</code> 文件下，在站点配置文件配置如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">skip_render: google10bb50e0b38f396b.html</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>产生 sitemap：借助  hexo-generator-sitemap 工具自动生成，并在<code>config.yml</code>里配置一下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-generator-sitemap --save</span><br></pre></td></tr></table></figure>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sitemap:</span><br><span class=\"line\">    path: sitemap.xml</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>重新编译生成</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo generate</span><br></pre></td></tr></table></figure>\n</li>\n</ol>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjo46iqiq00041wzmspy9o4rp","category_id":"cjo46iqiy00061wzmm8gqqfjm","_id":"cjo46iqj000091wzmsq4yxf4q"}],"PostTag":[{"post_id":"cjo46iqim00031wzmv57fqm29","tag_id":"cjo46iqiv00051wzm5k18533r","_id":"cjo46iqiz00081wzmhpj82xs7"},{"post_id":"cjo46iqiq00041wzmspy9o4rp","tag_id":"cjo46iqiz00071wzmjmgj7m2i","_id":"cjo46iqj0000a1wzm7lcjtinh"}],"Tag":[{"name":"Research","_id":"cjo46iqiv00051wzm5k18533r"},{"name":"Tools","_id":"cjo46iqiz00071wzmjmgj7m2i"}]}}